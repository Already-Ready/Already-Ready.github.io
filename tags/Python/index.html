<!DOCTYPE html>
<html  lang="en">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>Tag: Python - Hexo</title>


    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/tags/Python/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/images/og_image.png">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/images/og_image.png">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    
    
    
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    
    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="Hexo" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="/tags">Tags</a>
                
                <a class="navbar-item"
                href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-6-widescreen has-order-2 column-main"><div class="card">
    <div class="card-content">
        <nav class="breadcrumb" aria-label="breadcrumbs">
        <ul>
            <li><a href="/tags">Tags</a></li>
            <li class="is-active"><a href="#" aria-current="page">Python</a></li>
        </ul>
        </nav>
    </div>
</div>

    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-05-06T16:14:42.000Z">2020-05-06</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    8 minutes read (About 1266 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/05/06/Pytorch-visdom%EC%9C%BC%EB%A1%9C-Loss-plot%EA%B7%B8%EB%A6%AC%EA%B8%B0/">Pytorch_visdom으로_Loss_plot그리기</a>
            
        </h1>
        <div class="content">
            <h1 id="Visdom에-관하여-amp-Loss-plot-그리기"><a href="#Visdom에-관하여-amp-Loss-plot-그리기" class="headerlink" title="Visdom에 관하여 &amp; Loss plot 그리기"></a>Visdom에 관하여 &amp; Loss plot 그리기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>visdom을 사용하기 위해서는 서버를 실행시켜줘야 한다.</p>
</li>
<li><p>jupyter notebook의 경우, New –&gt; Terminal –&gt; 실행된 터미널 창에서 다음의 명령어를 입력한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;python -m visdom.server</span><br></pre></td></tr></table></figure>

<ul>
<li><p>pycharm을 이용한다면 파이참 하단의 terminal을 클릭해 위의 명령어를 입력하면된다.</p>
</li>
<li><p>다만, visdom의 기본 포트가 사용중이라면 에러가 발생하는데 이때는 <a href="https://already-ready.github.io/2020/04/25/%ED%8C%8C%EC%9D%B4%EC%8D%AC-visdom-port-%EB%B3%80%EA%B2%BD%ED%95%98%EA%B8%B0/">visdom 포트변경</a> 포스트를 확인해 해결할 수 있다.</p>
</li>
<li><p>서버가 정상적으로 실행됐다면, visdom 객체를 아래와 같이 생성하고 이를 이용해 text, 이미지, 그래프 등을 나타낼 수 있다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> visdom</span><br><span class="line">vis = visdom.Visdom()</span><br></pre></td></tr></table></figure>

<ul>
<li><p>아래에서 진행하는 예제는 실행된 local서버를 접속해 확인할 수 있다.</p>
</li>
<li><p>Text 출력하기</p>
<ul>
<li><p>text를 출력하기 위해서 <code>text()</code>를 사용한다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vis.text(<span class="string">'hello world'</span>, env=<span class="string">'main'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>이때 <code>env=&#39;main&#39;</code>은 실행문의 이름을 지정해 추후에 main으로 실행된 모든 창을 한번에 종료할 수 있게 해준다.</p>
</li>
</ul>
</li>
<li><p>Image 출력하기</p>
<ul>
<li><p>image 출력은 <code>image()</code>를 사용한다.</p>
</li>
<li><p>랜덤한 이미지를 출력해보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ex = torch.randn(<span class="number">3</span>, <span class="number">200</span>, <span class="number">200</span>)</span><br><span class="line">vis.image(ex)</span><br></pre></td></tr></table></figure>
</li>
<li><p>여러장의 이미지를 출력하기 위해서는 <code>images()</code>를 사용한다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vis.images(torch.Tensor(<span class="number">3</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">28</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>CIFAR10의 이미지를 가져와 출력해보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cifar10 = dsets.CIFAR10(root=<span class="string">"cifar10/"</span>,train = <span class="literal">True</span>, transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">data = cifar10.__getitem(<span class="number">0</span>)__</span><br><span class="line">vis.images(data[<span class="number">0</span>], env=<span class="string">'main'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>DataLoader로부터 여러개의 이미지를 출력할 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">MNIST = dsets.MNIST(root=<span class="string">"MNIST_data/"</span>,train = <span class="literal">True</span>,transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">data_loader = torch.utils.data.DataLoader(dataset = MNIST,</span><br><span class="line">                                         batch_size = <span class="number">32</span>,</span><br><span class="line">                                         shuffle = <span class="literal">False</span>)</span><br><span class="line">									  </span><br><span class="line"><span class="keyword">for</span> num, value <span class="keyword">in</span> enumerate(data_loader):</span><br><span class="line">	value = value[<span class="number">0</span>]</span><br><span class="line">	vis.images(value)</span><br><span class="line">	<span class="keyword">break</span></span><br><span class="line"><span class="comment">###&gt;&gt;&gt; batch_size만큼의 이미지가 한번에 출력된다</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Line Plot 그리기</p>
<ul>
<li><p>line plot은 <code>line()</code>을 사용한다.</p>
</li>
<li><p>임의의 y값을 가지는 그래프를 그려보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Y_data = torch.randn(<span class="number">5</span>)</span><br><span class="line">X_data = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">plt = vis.line(Y=Y_data, X=X_data)</span><br></pre></td></tr></table></figure>
</li>
<li><p>위를 통해 plt라는 이름의 그래프가 그려지는 것을 확인할 수 있다. 만약 이때 X 범위를 설정해주지 않았다면 X의 범위는 0과 1사이에서 출력되게 된다.</p>
</li>
<li><p>이미 그려진 line plot을 업데이트도 할 수 있다. 똑같이 <code>line()</code>을 사용한다. 위에서 그린 plt 그래프에 하나의 값을 업데이트 해보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Y_append = torch.randn(<span class="number">1</span>)</span><br><span class="line">X_append = torch.Tensor([<span class="number">6</span>])</span><br><span class="line"></span><br><span class="line">vis.line(Y=Y_append, X=X_append, win=plt, update=<span class="string">'append'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>위와같이 업데이트할 plot의 이름을 <code>win</code>에 지정해주고 <code>update=&#39;append&#39;</code>로 지정하면 기존의 그래프에 하나의 값이 추가된 것을 확인할 수 있다.</p>
</li>
<li><p>하나의 window에 두개의 line plot을 그릴때도 <code>line()</code>을 사용한다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">num = torch.Tensor(list(range(<span class="number">0</span>,<span class="number">10</span>)))</span><br><span class="line">num = num.view(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">num = torch.cat((num,num),dim=<span class="number">1</span>)</span><br><span class="line">print(num.shape) <span class="comment">###&gt;&gt;&gt; (10,2)</span></span><br><span class="line"></span><br><span class="line">plt = vis.line(Y=torch.randn(<span class="number">10</span>,<span class="number">2</span>), X = num)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Line Plot의 정보 나타내기</p>
<ul>
<li><p>line plot에 title과 legend를 나타내기 위해서는 dict형태의 입력값을 사용한다.</p>
</li>
<li><p>위에 그린 그래프에 title과 legned를 나타내보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt = vis.line(Y=Y_data, X=X_data, opts=dict(title=<span class="string">'test'</span>, legend=[<span class="string">'1번'</span>], showlegend=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>두개의 line plot에도 각각의 legend를 나타낼 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt = vis.line(Y=torch.randn(<span class="number">10</span>,<span class="number">2</span>), X=num, optes=dict(title=<span class="string">'test'</span>, legend=[<span class="string">'1번'</span>,<span class="string">'2번'</span>], showlegend=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>창 닫기</p>
<ul>
<li><p><code>env=&#39;main&#39;</code>으로 지정한 창을 닫기 위해서 <code>close()</code>를 사용한다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vis.close(env=<span class="string">'main'</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>기본적인 visdom 사용법을 알아보았으며, 이를 이용해 <a href="https://already-ready.github.io/2020/05/01/Pytorch-MNIST-CNN/">CNN MNIST</a>의 코드를 조금 변형해 loss plot을 그려보자.</p>
<ul>
<li><p>loss plot을 그리기 위해서 line plot을 업데이트해줄 함수를 만들어주자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_tracker</span><span class="params">(loss_plot, loss_value, num)</span>:</span></span><br><span class="line">	<span class="comment">### loss_plot : line plot value</span></span><br><span class="line">	<span class="comment">### loss_value : Tensor</span></span><br><span class="line">	<span class="comment">### num : Tensor</span></span><br><span class="line">	<span class="comment">### return : None</span></span><br><span class="line">	vis.line(X=num, Y=loss_value, win=loss_plot, update=<span class="string">'append'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>그리고 loss를 업데이트해줄 빈 line plot을 하나 만들어준다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_plot = vis.line(Y=torch.Tensor(<span class="number">1</span>).zero_(), opts=dict(title=<span class="string">'loss'</span>, legend=[<span class="string">'loss'</span>], showlegend=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>이후 모델 생성은 모두 동일하지만, train을 진행할때 위의 함수를 통해 그래프를 업데이트 해주는 부분이 추가된다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">total_batch = len(data_loader)</span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">	avg_cost = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> X, Y <span class="keyword">in</span> data_loader:</span><br><span class="line">		X = X.to(device)</span><br><span class="line">		Y = Y.to(device)</span><br><span class="line"></span><br><span class="line">		optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">		hypothesis = model(X)</span><br><span class="line">		loss = criterion(hypothesis, Y)</span><br><span class="line">		loss.backward()</span><br><span class="line">		optimizer.step()</span><br><span class="line"></span><br><span class="line">		avg_cost += loss / total_batch</span><br><span class="line"></span><br><span class="line">	print(<span class="string">'[Epoch: &#123;:&gt;4&#125;] cost = &#123;:&gt;.9&#125;'</span>.format(epoch + <span class="number">1</span>, avg_cost))</span><br><span class="line">	loss_tracker(loss_plot, torch.Tensor([avg_cost]), torch.Tensor([epoch])) </span><br><span class="line">	<span class="comment">###&gt;&gt;&gt; loss_tracker함수를 통해 그래프를 업데이트</span></span><br><span class="line">print(<span class="string">'learning finished'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>학습을 진행하면서 visdom의 line plot이 실시간으로 업데이트되는 모습을 확인할 수 있다.</p>
</li>
</ul>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/About_Visdom_example.py">Full Code - Visdom Example</a><br><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Convolution_with_Visdom.py">Full Code - Loss tracker</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-05-01T21:01:13.000Z">2020-05-01</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 549 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/05/01/Pytorch-MNIST-CNN/">Pytorch_MNIST_CNN</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-MNIST에-CNN모델-만들기"><a href="#Pytorch-MNIST에-CNN모델-만들기" class="headerlink" title="Pytorch MNIST에 CNN모델 만들기"></a>Pytorch MNIST에 CNN모델 만들기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>Convolution layer를 활용해서 MNIST이미지를 학습시킬 CNN 모델을 만들어보자.</p>
</li>
<li><p>아래 CNN 구조와 비슷한 모델을 설계해본다. </p>
</li>
<li><p><img src="https://github.com/Already-Ready/Already-Ready.github.io/blob/master/images/cnn.jpg?raw=true" alt="CNN 모델"></p>
</li>
<li><p><code>torch.nn.Sequential</code>을 통해 위의 그림에서 나타내는 각 layer와 Fully Connected layer를 표현할 수 있다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(CNN, self).__init__()</span><br><span class="line">        self.drop_prob = <span class="number">0.5</span></span><br><span class="line">		</span><br><span class="line">        self.layer1 = torch.nn.Sequential(</span><br><span class="line">            torch.nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.layer2 = torch.nn.Sequential(</span><br><span class="line">            torch.nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.layer3 = torch.nn.Sequential(</span><br><span class="line">            torch.nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        )</span><br><span class="line">        self.fc1 = torch.nn.Linear(<span class="number">3</span>*<span class="number">3</span>*<span class="number">128</span>, <span class="number">625</span>, bias=<span class="literal">True</span>)</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.fc1.weight)</span><br><span class="line"></span><br><span class="line">        self.layer4 = torch.nn.Sequential(</span><br><span class="line">            self.fc1,</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            torch.nn.Dropout(p=self.drop_prob)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.fc2 = torch.nn.Linear(<span class="number">625</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">        torch.nn.init.xavier_uniform_(self.fc2.weight)</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        output = self.layer1(x)</span><br><span class="line">		<span class="comment"># print(output.shape)</span></span><br><span class="line">        output = self.layer2(output)</span><br><span class="line">		<span class="comment"># print(output.shape)</span></span><br><span class="line">        output = self.layer3(output)</span><br><span class="line">		<span class="comment"># print(output.shape)</span></span><br><span class="line">        output = output.view(output.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        output = self.layer4(output)</span><br><span class="line">        output = self.fc2(output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>Conv2d</code>와 <code>MaxPool2d</code>을 지닌 layer를 통과하면서 output의 shape은 게속 변하게 된다.</p>
</li>
<li><p>이러한 과정에서 Fully Connected layer를 지날때는 이전 layer에서 나온 output의 shape를 알아야한다.</p>
</li>
<li><p>이때 <a href="https://already-ready.github.io/2020/04/30/Pytorch-Convolution-layer/">이전 포스트</a>에서 알아본 공식을 통해 output shape을 계산할 수 있다.</p>
</li>
<li><p>또한, forward를 진행하면서 각각의 layer를 통과한 output의 shape를 출력하면서 확인할 수도 있다.</p>
</li>
<li><p>CNN 모델을 배우기 전에는 선형함수만을 통해 MNIST이미지를 학습했다면 이번 과정에서는 지금까지 배운 <a href="https://already-ready.github.io/2020/04/18/Pytorch-Dropout/">Dropout</a>, <a href="https://already-ready.github.io/2020/04/16/Pytorch-weight-initialization/">weight initialization</a>, <a href="https://already-ready.github.io/2020/04/30/Pytorch-Convolution-layer/">Convolution layer</a> 등을 사용하는 모델을 만들 수 있었다.</p>
</li>
<li><p>학습과 평가는 기존 MNIST 학습 코드와 유사하고, Full Code 링크를 통해 확인할 수 있다.</p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Convolution.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-30T16:41:25.000Z">2020-04-30</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 669 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/30/Pytorch-Convolution-layer/">Pytorch_Convolution_layer</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Convolution-layer에-대하여"><a href="#Pytorch-Convolution-layer에-대하여" class="headerlink" title="Pytorch Convolution layer에 대하여"></a>Pytorch Convolution layer에 대하여</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>Convolution layer란 이미지 위에서 filter가 stride값만큼 움직이며 이미지와 filter가 겹쳐지는 부분의 각 원소의 값을 곱하고 모두 더한 값을 출력으로 하는 연산이다.</p>
</li>
<li><p>아래와 같은 이미지 위에서 stride가 1인 filter가 움직이며 나타나는 출력을 계산해보자.</p>
</li>
<li><p><img src="https://datascienceplus.com/wp-content/uploads/2019/02/convolved-matrix.gif" alt="Convolution"></p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">위의 그림에서 아래와 같은 필터를 사용했을 때 나오는 결과값을 하나 계산해보자</span><br><span class="line"></span><br><span class="line">filter = [[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">		   [<span class="number">0</span>,<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">		   [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>x3필터가 이미지와 처음 겹쳐졌을 때 다음과 같은 연산이 수행된다.</span><br><span class="line"></span><br><span class="line">output = (<span class="number">1</span>*<span class="number">1</span>) + (<span class="number">0</span>*<span class="number">1</span>) + (<span class="number">1</span>*<span class="number">1</span>) +</span><br><span class="line">		 (<span class="number">0</span>*<span class="number">0</span>) + (<span class="number">1</span>*<span class="number">1</span>) + (<span class="number">0</span>*<span class="number">1</span>) +</span><br><span class="line">		 (<span class="number">1</span>*<span class="number">0</span>) + (<span class="number">0</span>*<span class="number">0</span>) + (<span class="number">1</span>*<span class="number">1</span>) = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">따라서, 우측 Convolution Feature의 처음 값이 <span class="number">4</span>로 나타나는 것을 확인할 수 있고, 이후에도 stride가 <span class="number">1</span>이므로, 한칸씩 움직이며 같은 연산을 반복한다.</span><br></pre></td></tr></table></figure>

<ul>
<li><p>zero-padding</p>
<ul>
<li><p>zero-padding이란 이미지 주변에 패드를 끼우듯 0으로 채워진 테두리를 둘러 inpute size를 키워주는 것이다.</p>
</li>
<li><p>zero-padding을 사용하는 이유는 Convolution layer를 지났을 때 이미지의 크기를 보존해주기 위해서다.</p>
</li>
<li><p>위에서 우리는 3x3 의 filter를 사용한 결과, 원래 이미지의 크기가 5x5에서 3x3으로 줄어든 것을 볼 수 있었다.</p>
</li>
<li><p>이와같은 Convolution layer를 반복적으로 지날때 이미지의 크기가 작아져서 정보의 손실이 생기게된다.</p>
</li>
<li><p>하지만, zero-padding을 이용해 원본 이미지의 size를 키워서 Convolution layer를 지나게 한다면, 원본 이미지의 크기를 보존시켜 정보의 손실을 최소화할 수 있게된다.</p>
</li>
<li><p><img src="https://deeplizard.com/images/zero%20padding%20example%202.PNG" alt="Convolution with zero-padding"></p>
</li>
<li><p>위의 그림에서 Input size가 Output에서도 보존되는것을 확인할 수 있다.<br><br></br></p>
</li>
</ul>
</li>
<li><p>Output size 계산하기</p>
<ul>
<li><p>Convolution layer를 지나쳤을때 나오는 output size는 input size, filter size, stride, padding에 의해 결정되며, 다음과 같은 공식을 따른다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output size = ((input size - filter size + (<span class="number">2</span>*padding)) / strid) + <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>위의 이미지를 예시로 계산해보면 다음과 같다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output size = ((<span class="number">4</span>x4 - <span class="number">3</span>x3 + (<span class="number">2</span>*<span class="number">1</span>)) / <span class="number">1</span>) + <span class="number">1</span> = (<span class="number">1</span>x1 + <span class="number">2</span>) + <span class="number">1</span> = (<span class="number">3</span>x3)+<span class="number">1</span> = <span class="number">4</span>x4</span><br></pre></td></tr></table></figure>
</li>
<li><p>input size의 높이와 넓이가 다를때도 동일하게 계산할 수 있다.</p>
</li>
<li><p>이처럼 하나의 Convolution layer를 통과했을 때 나오는 output size를 계산할 수 있고 이를 다음 layer의 입력값으로 활용할 수 있게된다.</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>참고</p>
<ul>
<li><a href="https://datascienceplus.com/starting-with-convolutional-neural-network-cnn/">Convolution layer 이미지</a></li>
<li><a href="https://deeplizard.com/learn/video/qSTv_m-KFk0">padding 이미지</a></li>
</ul>
</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-25T23:14:37.000Z">2020-04-25</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/About-Python/">About Python</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    3 minutes read (About 484 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/25/%ED%8C%8C%EC%9D%B4%EC%8D%AC-visdom-port-%EB%B3%80%EA%B2%BD%ED%95%98%EA%B8%B0/">파이썬_visdom_port_변경하기</a>
            
        </h1>
        <div class="content">
            <h1 id="파이썬-visdom의-port-변경하기"><a href="#파이썬-visdom의-port-변경하기" class="headerlink" title="파이썬 visdom의 port 변경하기"></a>파이썬 visdom의 port 변경하기</h1><ul>
<li><p>visdom의 기본포트는 8097포트이다.</p>
</li>
<li><p>CNN모델 학습 Loss그래프를 그리기 위해 visdom을 사용하려 했으나 다음과 같은 에러가 발생했다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">액세스 권한에 의해 숨겨진 소켓에 액세스를 시도했습니다</span><br></pre></td></tr></table></figure>

<ul>
<li><p>이는 이미 8097포트를 다른 프로세스에서 사용하고 있기 때문에 발생한다.</p>
</li>
<li><p>따라서, 해당 프로세스를 찾아야하는데 cmd에 다음과 같은 명령어로 사용중인 포트와 프로세스를 확인할 수 있다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -ano</span><br></pre></td></tr></table></figure>

<ul>
<li><p>해당 프로세스를 찾았으면 좌측 끝의 PID를 확인하고 작업 관리자를 열어주자.</p>
</li>
<li><p>작업 관리자 –&gt; 서비스 탭에 들어가면 PID로 프로세스를 정렬할 수 있다.</p>
</li>
<li><p>그곳에서 포트를 사용중인 프로세르를 선택하고 서비스 센터로 접근해 작업을 종료하면 된다.</p>
</li>
<li><p>이후 다시,</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m visdom.server</span><br></pre></td></tr></table></figure>

<ul>
<li><p>명령어로 visdom 로컬 서버를 키면된다.</p>
</li>
<li><p>하지만, 8097 포트를 사용하는 프로세스를 찾을 수가 없었다.</p>
</li>
<li><p>방화벽 문제인지 공유기 문제인지 확실하지는 못했지만 원인을 찾을수가 없었기에 visdom의 포트를 변경해서 사용하기로 결정했다.</p>
</li>
<li><p>visdom의 포트는 다음과 같이 변경할 수 있다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m visdom.server -port [포트번호]</span><br></pre></td></tr></table></figure>

<ul>
<li>예를들어, 포트번호를 9000으로 옮긴다면 다음과 같이 바꿀 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python -m visdom.server -port <span class="number">9000</span></span><br></pre></td></tr></table></figure>

<ul>
<li>이제 코드에서 visdom 객체를 불러올 때 다음과 같이 정한 포트 번호를 사용해서 불러오기만 하면 된다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vis = visdom.Visdom(port=<span class="number">9000</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>아래 예제를 실행해서 올바르게 출력되는것을 확인할 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vis.text(<span class="string">'hello world'</span>, env=<span class="string">"main"</span>)</span><br></pre></td></tr></table></figure>
        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-21T21:01:37.000Z">2020-04-21</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    6 minutes read (About 839 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/21/Pytorch-Batch-Normalization/">Pytorch_Batch_Normalization</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Batch-Normalization에-대하여"><a href="#Pytorch-Batch-Normalization에-대하여" class="headerlink" title="Pytorch Batch Normalization에 대하여"></a>Pytorch Batch Normalization에 대하여</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>overfitting과 gradient vanishing문제를 해결하기 위해 앞서서 <a href="https://already-ready.github.io/2020/04/14/Pytorch-ReLU/">ReLU 포스트</a>와 <a href="https://already-ready.github.io/2020/04/18/Pytorch-Dropout/">Dropout 포스트</a>를 적었었다.  </p>
</li>
<li><p>이번 포스트에서는 또 다른 방법인 Batch Normalization방법을 정리하고자 한다.   </p>
</li>
<li><p>Batch Normalization은 모델이 깊어질수록 나타나는 Internal Covariate Shift를 해결하면서 등장했다.</p>
</li>
<li><p>Internal Covariate Shift란 모델이 깊어질수록 output의 분포가 편향되는 문제를 말합니다.</p>
</li>
<li><p>이를 해결하기 위해 Batch마다 output을 Normalization하는 방식이 등장합니다. </p>
</li>
<li><p>Batch Normalization도 dropout과 똑같이 <code>train()</code>과 <code>eval()</code>을 구분지어서 사용해야 합니다.</p>
</li>
<li><p>왜냐하면, Batch Normalization을 통해 <code>평균, 분산</code>과 학습하는 데이터 <code>scale값 감마, shift값 베타</code>를 저장해서 사용하기 때문입니다.</p>
</li>
<li><p>따라서, 학습을 위해서는 dropout때와 마찬가지로 <code>train()</code>함수를, 평가를 위해서는 저장된 값을 이용하기 위해 <code>eval()</code>함수를 먼저 작성해야합니다.</p>
</li>
<li><p>Batch Normalization은 dropout과 다르게 활성화 함수 이전에 적용시킵니다.</p>
</li>
<li><p>이를 이용해 Batch Normalization을 사용한 경우와, 사용하지 않은 경우를 비교해 보겠습니다.</p>
</li>
<li><p><a href="https://already-ready.github.io/2020/04/18/Pytorch-Dropout/">Dropout 포스트</a>때와 유사하지만 Batch Normalization을 다음과 같이 만들어서 두 가지 모델을 정의했습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">linear1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">32</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear2 = torch.nn.Linear(<span class="number">32</span>, <span class="number">32</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear3 = torch.nn.Linear(<span class="number">32</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">relu = torch.nn.ReLU()</span><br><span class="line">bn1 = torch.nn.BatchNorm1d(<span class="number">32</span>)</span><br><span class="line">bn2 = torch.nn.BatchNorm1d(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># BatchNorm을 사용하지 않는 모델을 만들기 위한 Linear layer 만들기</span></span><br><span class="line">nn_linear1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">32</span>, bias=<span class="literal">True</span>)</span><br><span class="line">nn_linear2 = torch.nn.Linear(<span class="number">32</span>, <span class="number">32</span>, bias=<span class="literal">True</span>)</span><br><span class="line">nn_linear3 = torch.nn.Linear(<span class="number">32</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 정의</span></span><br><span class="line">bn_model = torch.nn.Sequential(linear1, bn1, relu,</span><br><span class="line">                               linear2, bn2, relu,</span><br><span class="line">                               linear3).to(device)</span><br><span class="line">nn_model = torch.nn.Sequential(linear1, relu,</span><br><span class="line">                               linear2, relu,</span><br><span class="line">                               linear3).to(device)</span><br></pre></td></tr></table></figure>

<ul>
<li>이후, 학습을 진행할 때 각 epoch마다 평가를 진행하면서 Loss와 Accuracy를 저장시켜 line plot을 그려 비교해 보겠습니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 학습 &amp; 각epoch 마다 평가</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    bn_model.train()</span><br><span class="line">    <span class="keyword">for</span> X, Y <span class="keyword">in</span> train_loader:</span><br><span class="line">        X = X.view(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        Y = Y.to(device)</span><br><span class="line">		.</span><br><span class="line">		.</span><br><span class="line">		.</span><br><span class="line">	<span class="keyword">with</span> torch.no_grad():</span><br><span class="line">		bn_model.eval()</span><br><span class="line"></span><br><span class="line">		<span class="comment"># train셋을 통한 평가</span></span><br><span class="line">		bn_loss, nn_loss, bn_Acc, nn_Acc = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">		<span class="keyword">for</span> i, (X, Y) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">			X = X.view(<span class="number">-1</span>, <span class="number">28</span> * <span class="number">28</span>).to(device)</span><br><span class="line">			Y = Y.to(device)</span><br><span class="line">			.</span><br><span class="line">			.</span><br><span class="line">			.</span><br><span class="line">		<span class="comment"># test셋을 통한 평가</span></span><br><span class="line">        bn_loss, nn_loss, bn_Acc, nn_Acc = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i, (X, Y) <span class="keyword">in</span> enumerate(test_loader):</span><br><span class="line">            X = X.view(<span class="number">-1</span>, <span class="number">28</span> * <span class="number">28</span>).to(device)</span><br><span class="line">            Y = Y.to(device)</span><br><span class="line">			.</span><br><span class="line">			.</span><br><span class="line">			.</span><br></pre></td></tr></table></figure>

<ul>
<li><p>이후 train과 validation의 Loss와 Accuracy를 Line Plot으로 그려 확인할 수 있었습니다.</p>
</li>
<li><p><img src="https://github.com/Already-Ready/Already-Ready.github.io/blob/master/images/training%20loss.png?raw=true" alt="training Loss"></p>
</li>
<li><p><img src="https://github.com/Already-Ready/Already-Ready.github.io/blob/master/images/training%20acc.png?raw=true" alt="training Acc"></p>
</li>
<li><p><img src="https://github.com/Already-Ready/Already-Ready.github.io/blob/master/images/validation%20loss.png?raw=true" alt="validation Loss"></p>
</li>
<li><p><img src="https://github.com/Already-Ready/Already-Ready.github.io/blob/master/images/validation%20acc.png?raw=true" alt="validation Acc"></p>
</li>
<li><p>그림에서도 확인할 수 있듯이 Batch Normalization을 적용했을 때, validation의 Loss가 더 작은것을 확인할 수 있었습니다.</p>
</li>
<li><p>데이터 로딩 ~ 이미지 생성까지 생략된 부분은 아래 Full Code를 확인해주세요.</p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Batch_Normalization.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-18T22:57:35.000Z">2020-04-18</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    7 minutes read (About 1108 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/18/Pytorch-Dropout/">Pytorch_Dropout</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Dropout에-대하여"><a href="#Pytorch-Dropout에-대하여" class="headerlink" title="Pytorch Dropout에 대하여"></a>Pytorch Dropout에 대하여</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>Dropout은 모델의 layer가 많아질때 생기는 overfitting문제를 해결하기 위해 사용된다.  </p>
</li>
<li><p>overfitting이란 train데이터를 모델이 지나치게 정확히 학습하는 바람에 모델이 test데이터에서는 좋은 결과를 내놓지 못하는 경우이다.  </p>
</li>
<li><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/300px-Overfitting.svg.png" alt="overfitting">  </p>
</li>
<li><p>위 그림에서 초록색선을 보면 빨간점과 파란점을 완벽하게 분류하는 것을 확인할 수 있다. 이렇게 train 데이터에 지나치게 학습된 경우를 overfitting이라하며, 적절한 학습의 정도를 까만선이 나타내고 있다.  </p>
</li>
<li><p>이러한 overfitting문제를 해결하기 위해 dropout을 사용하게 된다.  </p>
</li>
<li><p>dropout이란 forward함수를 통해 train데이터가 layer를 지날때 뉴런 일부를 생략하고 학습을 진행하는것이다.  </p>
</li>
<li><p><img src="https://miro.medium.com/max/1400/1*iWQzxhVlvadk6VAJjsgXgg.png" alt="dropout">  </p>
</li>
<li><p>위의 우측 그림과 같이 layer마다 임의의 뉴런을 생략하고 학습을 진행하는 것을 볼 수 있다.  </p>
</li>
<li><p>사용자가 정의한 비율만큼의 뉴런을 생략하고 학습을 진행할 때, 매 epoch마다 다른 뉴런들이 꺼졌다가 켜지기를 반복하게 된다.  </p>
</li>
<li><p>이는 매번 다른 모델을 학습하는것과 유사하기 때문에 Ensemble(앙상블)효과를 기대할 수도 있다.  </p>
</li>
<li><p>dropout을 사용할 때는 non-linear 활성화 함수 다음에 사용하게 된다.  </p>
</li>
<li><p>MNIST 데이터셋을 이용해 활용법을 살펴보자.  </p>
</li>
<li><p>통과할 linear 와 relu 그리고 dropout을 설정해준다.  </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nn Linear layer / relu / dropout 만들기</span></span><br><span class="line">linear1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">512</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear2 = torch.nn.Linear(<span class="number">512</span>, <span class="number">512</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear3 = torch.nn.Linear(<span class="number">512</span>, <span class="number">512</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear4 = torch.nn.Linear(<span class="number">512</span>, <span class="number">512</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear5 = torch.nn.Linear(<span class="number">512</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">relu = torch.nn.ReLU()</span><br><span class="line">dropout = torch.nn.Dropout(p=drop_prob) <span class="comment"># drop_prob = 0.3 in my code</span></span><br></pre></td></tr></table></figure>

<ul>
<li>이를 이용해 모델을 만들때 선형함수를 통과하고 활성화 함수를 지난 뒤에 dropout을 적용해준다.  </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = torch.nn.Sequential(linear1, relu, dropout, linear2, relu, dropout,</span><br><span class="line">                            linear3, relu, dropout, linear4, relu, dropout,</span><br><span class="line">                            linear5).to(device)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>이렇게 만들어진 모델로 학습과 평가를 똑같이 진행할 수 없다.  </p>
</li>
<li><p>왜냐하면 학습 이후 평가할 때 dropout이 켜져있다면 모든 weight를 사용하지 않고 output을 내게 되기 때문이다.  </p>
</li>
<li><p>이렇게 dropout은 학습할때는 사용하고, 평가를 위해서는 사용하지 말아야한다.  </p>
</li>
<li><p>이를 조절할 수 있는 함수가 <code>train()</code>함수와 <code>eval()</code>함수이다.  </p>
</li>
<li><p>다음고 같이 <code>train()</code>함수를 통해 dropout을 사용하겠다는 표시를 한 후, 학습을 진행해야 한다.  </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">model.train() <span class="comment"># train() 함수를 사용하면 dropout=True로 설정된다.</span></span><br><span class="line"><span class="comment"># 즉 학습할때 사용해야하고 추후 모델을 평가할때는 eval()함수를 꼭 설정해줘야한다.</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    avg_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, Y <span class="keyword">in</span> data_loader:</span><br><span class="line">        X = X.view(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        Y = Y.to(device)</span><br><span class="line"></span><br><span class="line">        hypothesis = model(X)</span><br><span class="line">        loss = criterion(hypothesis, Y)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        avg_loss += loss / total_batch</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Epoch:'</span>, <span class="string">'%04d'</span> % (epoch + <span class="number">1</span>), <span class="string">'cost ='</span>, <span class="string">'&#123;:.9f&#125;'</span>.format(avg_loss))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Learning finished'</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>학습을 마친 후, 랜덤한 하나의 데이터를 통해 결과를 확인해 보고 싶다면 다음과 같이 <code>eval()</code>함수를 통해 dropout을 사용하지 않겠다고 표시한 후 평가를 진행해야 한다.  </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad(): <span class="comment"># --&gt; 여기에서는(test에서는) gradient를 계산하지 않고 진행한다는 뜻이다.</span></span><br><span class="line">    model.eval() <span class="comment"># --&gt; eval() 함수를 사용하면 dropout=False 로 설정되서 모든 노드를 사용해 모델을 평가하게된다.</span></span><br><span class="line">    X_test = mnist_test.test_data.view(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>).float().to(device)</span><br><span class="line">    Y_test = mnist_test.test_labels.to(device)</span><br><span class="line"></span><br><span class="line">    prediction = model(X_test)</span><br><span class="line">    correct_prediction = torch.argmax(prediction, dim=<span class="number">1</span>) == Y_test</span><br><span class="line">    accuracy = correct_prediction.float().mean()</span><br><span class="line">    print(<span class="string">'Accuracy:'</span>, accuracy.item())</span><br><span class="line"></span><br><span class="line">    r = random.randint(<span class="number">0</span>, len(mnist_test) - <span class="number">1</span>)</span><br><span class="line">    X_single_data = mnist_test.test_data[r:r + <span class="number">1</span>].view(<span class="number">-1</span>, <span class="number">28</span> * <span class="number">28</span>).float().to(device)</span><br><span class="line">    Y_single_data = mnist_test.test_labels[r:r + <span class="number">1</span>].to(device)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Label: '</span>, Y_single_data.item())</span><br><span class="line">    single_prediction = model(X_single_data)</span><br><span class="line">    print(<span class="string">'Prediction: '</span>, torch.argmax(single_prediction, <span class="number">1</span>).item())</span><br></pre></td></tr></table></figure>

<ul>
<li><p>첫째로, dropout은 non-linear 활성화 함수 다음에 사용한다는 점</p>
</li>
<li><p>둘째로, 학습과 평가를 위해서는 <code>train()</code>함수와 <code>eval()</code>함수를 반드시 사용해야 된다는 것을 기억해야겠다.</p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/dropout_MNIST.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-16T19:56:28.000Z">2020-04-16</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 624 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/16/Pytorch-weight-initialization/">Pytorch_weight_initialization</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Weight-initialization에-대하여"><a href="#Pytorch-Weight-initialization에-대하여" class="headerlink" title="Pytorch Weight initialization에 대하여"></a>Pytorch Weight initialization에 대하여</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>모델을 학습하기 이전에 weight의 초기값을 설정하는 문제는 모델의 학습에 굉장히 중요한 문제였습니다.</p>
</li>
<li><p>초기에 이 문제를 해결하기 위해서 사용했던 방법은 RBM(restricted boltzmann machine)이었습니다.</p>
</li>
<li><p>RBM은 layer1과 다음 레이어 layer2를 통해 weight1을 학습한 후 w1을 고정한 상태에서 layer2와 layer3를 통해 weight2를 학습하는 과정을 반복하는 방법입니다.</p>
</li>
<li><p><img src="http://www.todaysoftmag.ro/tsm/images/articles/tsm20/a22.png" alt="RBM"></p>
</li>
<li><p>하지만, 요즘에는 새로운 initialization 방법들이 제안되면서 RBM을 많이 사용하지 않고 있습니다.</p>
</li>
<li><p>대표적으로 간단히 initialization할 수 있는 두 가지 방법인 Xavier / He initialization 에 대해 알아보겠습니다.</p>
</li>
<li><p><a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_"><strong>Xavier initialization</strong></a></p>
<ul>
<li><p>Xavier / He initialization 모두 Normal initialization 방법과 Uniform initialization 방법을 가지고 있으며 모두 간단한 수식을 통해 이루어집니다.</p>
</li>
<li><p>Xavier Normal initialization</p>
<script type="math/tex; mode=display">W\sim N({ 0 }, Var(W))</script>

<script type="math/tex; mode=display">Var(W)=\sqrt{\frac { 2 }{ { n }_{ in }+{ n }_{ out } } }</script>
</li>
<li><p>n<sub>in</sub>은 layer의 input수, n<sub>out</sub>은 layer의 output수를 뜻합니다.<br><br></br></p>
</li>
<li><p>Xavier Uniform initialization</p>
<script type="math/tex; mode=display">W\sim U(- \sqrt{\frac { 6 }{ { n }_{ in }+{ n }_{ out } } } , \space\space + \sqrt{\frac { 6 }{ { n }_{ in }+{ n }_{ out } } } )</script>
</li>
<li><p>n<sub>in</sub>은 layer의 input수, n<sub>out</sub>은 layer의 output수를 뜻합니다.<br><br></br></p>
</li>
</ul>
</li>
<li><p><a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_"><strong>He initialization</strong></a></p>
<ul>
<li><p>He Normal initialization</p>
<script type="math/tex; mode=display">W\sim N({ 0 }, Var(W))</script>

<script type="math/tex; mode=display">Var(W)=\sqrt{\frac { 2 }{ { n }_{ in } } }</script> 
</li>
<li><p>n<sub>in</sub>은 layer의 input수를 뜻합니다.<br><br></br></p>
</li>
<li><p>He Uniform initialization</p>
<script type="math/tex; mode=display">W\sim U(- \sqrt{\frac { 6 }{ { n }_{ in } } } , \space\space + \sqrt{\frac { 6 }{ { n }_{ in } } } )</script>
</li>
<li><p>n<sub>in</sub>은 layer의 input수를 뜻합니다.  </p>
</li>
</ul>
</li>
<li><p>Pytorch에서는 <code>torch.nn.init</code>패키지를 통해서 사용할 수 있습니다.</p>
</li>
<li><p><a href="https://already-ready.github.io/2020/04/14/Pytorch-ReLU/">ReLU</a>에 관해서 작성한 포스트에서 작성한 코드와 달라진 점은 weight를 초기화해주는 부분뿐입니다.</p>
</li>
<li><p>먼저 linear layer를 만들고,</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">linear1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear2 = torch.nn.Linear(<span class="number">256</span>, <span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear3 = torch.nn.Linear(<span class="number">256</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">relu = torch.nn.ReLU()</span><br></pre></td></tr></table></figure>

<ul>
<li>다음과 같이 xavier_uniform으로 초기화 할 수 있습니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.init.xavier_uniform_(linear1.weight)</span><br><span class="line">torch.nn.init.xavier_uniform_(linear2.weight)</span><br><span class="line">torch.nn.init.xavier_uniform_(linear3.weight)</span><br></pre></td></tr></table></figure>

<ul>
<li><a href="https://already-ready.github.io/2020/04/14/Pytorch-ReLU/">ReLU</a> 포스트의 코드와 다른점은 weight initialization뿐이지만 Accuracy가 상승된것을 확인할 수 있습니다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/xavier_initialization_MNIST.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-14T16:26:50.000Z">2020-04-14</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    6 minutes read (About 930 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/14/Pytorch-ReLU/">Pytorch_ReLU</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-ReLU에-대하여"><a href="#Pytorch-ReLU에-대하여" class="headerlink" title="Pytorch ReLU에 대하여"></a>Pytorch ReLU에 대하여</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p><a href="https://already-ready.github.io/2020/04/08/Pytorch-Logistic-regression/">이전 포스팅</a>에서 두 가지 클래스를 분류하는 모델을 만들때 sigmoid함수를 사용했습니다.</p>
</li>
<li><p>하지만, sigmoid함수에는 모델이 깊어질수록 vanishing Gradient문제가 발생하게 됩니다.</p>
</li>
<li><p>vanishing Gradient란, 역전파를 통해 gradient를 전파받을 때, 0에 근접한 값들이 곱해짐에 따라 앞단으로 갈수록 gradient가 사라지게 되는 문제입니다.</p>
</li>
<li><p>이러한 문제가 생기는 이유는 sigmoid 함수 그래프를 통해 확인할 수 있습니다.</p>
</li>
<li><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png" alt="sigmoid 그래프"></p>
</li>
<li><p>sigmoid 그래프의 양 극단으로 갈수록 기울기는 0에 수렴하게 되는것을 볼 수 있고, 이때문에 역전파를 통해 gradient가 곱해질 때마다 그 값 또한 0으로 수렴하게 됩니다.</p>
</li>
<li><p>따라서 아래 그림과 같이 역전파가 깊이 전달될수록 gradient가 사라지는 vanishing gradient 문제가 발생하게 됩니다.</p>
</li>
<li><p><img src="https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F278186%2Fd158ec3585bc1551d9f3a03ae13a3a73%2Fvanishing%20gradient%20problem.png?generation=1574233763365617&alt=media" alt="vanishing Gradient"></p>
</li>
<li><p>이러한 문제를 해결하기 위해 Hinton교수님이 찾아낸 방법이 바로 ReLU 입니다.</p>
</li>
<li><p>ReLU를 수식으로 나타내면 다음과 같습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f(x) = max(<span class="number">0</span>, x)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>입력값 x가 들어왔을때, 0보다 크다면 자기자신을 그렇지 않다면 0을 되돌려주는것이 바로 ReLU입니다.</p>
</li>
<li><p>코드에서 활성화 함수만 sigmoid에서 ReLU로 바꾸면 되기때문에 ReLU를 이용한 MNIST classifier 를 만들어보겠습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nn Linear layer 만들기</span></span><br><span class="line">linear1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear2 = torch.nn.Linear(<span class="number">256</span>, <span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear3 = torch.nn.Linear(<span class="number">256</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">relu = torch.nn.ReLU()</span><br></pre></td></tr></table></figure>

<ul>
<li>Linear layer와 활성화 함수로 사용할 ReLU를 정의해주고, Linear layer의 weight를 normalization 합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Linear layer의 weight를 normalization시켜주기</span></span><br><span class="line">torch.nn.init.normal_(linear1.weight)</span><br><span class="line">torch.nn.init.normal_(linear2.weight)</span><br><span class="line">torch.nn.init.normal_(linear3.weight)</span><br></pre></td></tr></table></figure>

<ul>
<li>위를 이용해 모델을 정의하고,</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델 정의</span></span><br><span class="line">model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)</span><br><span class="line"><span class="comment">###&gt;&gt;&gt; 왜 linear3다음에는 relu를 하지않는가</span></span><br><span class="line"><span class="comment">###&gt;&gt;&gt; 우리가 사용할 criterion은 CrossEntropyLoss인데 여기에는 마지막에 softmax activation이 포함되어 있기 때문이다.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>loss / optimizer 를 정의합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loss / optimizer 정의</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss().to(device)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<ul>
<li>정한 epoch수만큼 모델을 학습시킵니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">total_batch = len(data_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    avg_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, Y <span class="keyword">in</span> data_loader:</span><br><span class="line">        X = X.view(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        Y = Y.to(device)</span><br><span class="line"></span><br><span class="line">        hypothesis = model(X)</span><br><span class="line">        loss = criterion(hypothesis, Y)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        avg_loss += loss / total_batch</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Epoch:'</span>, <span class="string">'%04d'</span> % (epoch + <span class="number">1</span>), <span class="string">'cost ='</span>, <span class="string">'&#123;:.9f&#125;'</span>.format(avg_loss))</span><br></pre></td></tr></table></figure>

<ul>
<li>학습이 끝났다면 테스트 데이터에서 하나를 선택해 예측값과 실제값을 비교해 결과를 확인해봅니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad(): <span class="comment"># --&gt; 여기에서는(test에서는) gradient를 계산하지 않고 진행한다는 뜻이다.</span></span><br><span class="line">    X_test = mnist_test.test_data.view(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>).float().to(device)</span><br><span class="line">    Y_test = mnist_test.test_labels.to(device)</span><br><span class="line"></span><br><span class="line">    prediction = model(X_test)</span><br><span class="line">    correct_prediction = torch.argmax(prediction, dim=<span class="number">1</span>) == Y_test</span><br><span class="line">    accuracy = correct_prediction.float().mean()</span><br><span class="line">    print(<span class="string">'Accuracy:'</span>, accuracy.item())</span><br><span class="line"></span><br><span class="line">    r = random.randint(<span class="number">0</span>, len(mnist_test) - <span class="number">1</span>)</span><br><span class="line">    X_single_data = mnist_test.test_data[r:r + <span class="number">1</span>].view(<span class="number">-1</span>, <span class="number">28</span> * <span class="number">28</span>).float().to(device)</span><br><span class="line">    Y_single_data = mnist_test.test_labels[r:r + <span class="number">1</span>].to(device)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Label: '</span>, Y_single_data.item())</span><br><span class="line">    single_prediction = model(X_single_data)</span><br><span class="line">    print(<span class="string">'Prediction: '</span>, torch.argmax(single_prediction, <span class="number">1</span>).item())</span><br></pre></td></tr></table></figure>

<ul>
<li>하나의 데이터를 통해 예측값과 실제값까지 확인해볼 수 있었습니다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/MNIST_nn_ReLU.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-13T15:45:13.000Z">2020-04-13</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 593 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/13/Pytorch-Softmax-classification/">Pytorch_Softmax_classification</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Softmax-Classificaton-을-통한-N개의-이벤트-분류하기"><a href="#Pytorch-Softmax-Classificaton-을-통한-N개의-이벤트-분류하기" class="headerlink" title="Pytorch Softmax Classificaton 을 통한 N개의 이벤트 분류하기"></a>Pytorch Softmax Classificaton 을 통한 N개의 이벤트 분류하기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p><a href="https://already-ready.github.io/2020/04/08/Pytorch-Logistic-regression/">binary classificaton</a> 문제를 해결할 때 sigmoid함수를 사용했습니다.</p>
</li>
<li><p>정확히는 <code>F.binary_cross_entropy</code> 안에 sigmoid함수가 같이 녹아있는 형태로 loss함수를 사용했습니다.</p>
</li>
<li><p>하지만, 세개 이상의 분류문제를 해결하기 위해서는 <code>sigmoid</code>함수가 아닌 <code>softmax</code>함수를 사용해야 합니다.</p>
</li>
<li><p>softmax함수는 아래와 같은 식으로 나타낼 수 있습니다.</p>
</li>
<li><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bdc1f8eaa8064d15893f1ba6426f20ff8e7149c5" alt="softmax"></p>
</li>
<li><p>K개의 입력값을 0~1 사이의 값이 되도록 K개의 SUM으로 나눠주게 됩니다. 따라서 모든 확률의 합은 1이됩니다. 또한 입력값의 순서가 출력값의 순서와 같음을 확인할 수 있습니다.</p>
</li>
<li><p>이제 Pytorch를 통해 SoftmaxClassifierModel을 정의해 보았습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델 정의</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftmaxClassifierModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="number">16</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.linear(x)</span><br><span class="line"></span><br><span class="line">model = SoftmaxClassifierModel()</span><br></pre></td></tr></table></figure>

<ul>
<li><p>모델을 정의한 내용을 보면 입력값X에 따른 Linear함수만을 통과하고 Softmax함수를 통과하지 않는것을 볼 수 있습니다.</p>
</li>
<li><p>이는 loss함수에서 사용하게 될 <code>F.cross_entropy</code>에 Softmax함수가 포함되어 있기 때문입니다.</p>
</li>
<li><p>따라서 정의한 모델에서는 Softmax를 통과하기전의 Linear함수를 통과한 output값을 되돌려줘야 합니다.</p>
</li>
<li><p>optimizer를 정의하고,</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># optimizer 정의</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>정한 epoch수 만큼 학습하며 loss를 출력해봅니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 학습</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs + <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">    predict = model(x_train)</span><br><span class="line">    loss = F.cross_entropy(predict, y_train)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Epoch &#123;:4d&#125;/&#123;&#125; loss : &#123;:.6f&#125;'</span>.format(</span><br><span class="line">            epoch, epochs, loss.item()</span><br><span class="line">        ))</span><br><span class="line">		</span><br><span class="line"><span class="comment">###&gt;&gt;&gt;print</span></span><br><span class="line">Epoch    <span class="number">0</span>/<span class="number">1000</span> loss : <span class="number">1.721660</span></span><br><span class="line">Epoch  <span class="number">100</span>/<span class="number">1000</span> loss : <span class="number">0.462462</span></span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">Epoch  <span class="number">900</span>/<span class="number">1000</span> loss : <span class="number">0.110220</span></span><br><span class="line">Epoch <span class="number">1000</span>/<span class="number">1000</span> loss : <span class="number">0.100880</span></span><br></pre></td></tr></table></figure>

<ul>
<li>출력된 loss를 통해 모델이 정상적으로 학습되는것을 확인할 수 있습니다. 이처럼 N개의 이벤트를 분류할 경우는 Softmax함수를 두개의 이벤트를 분류할 경우는 Sigmoid함수를 사용한다는것을 배울 수 있었습니다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/softmax_classification.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-10T01:20:19.000Z">2020-04-10</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    6 minutes read (About 961 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/10/Pytorch-Multi-Layer-Perceptron-MLP/">Pytorch_Multi_Layer_Perceptron_MLP</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Multi-Layer-Perceptron-MLP-에-관하여-with-code"><a href="#Pytorch-Multi-Layer-Perceptron-MLP-에-관하여-with-code" class="headerlink" title="Pytorch Multi Layer Perceptron(MLP)에 관하여 with code"></a>Pytorch Multi Layer Perceptron(MLP)에 관하여 with code</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><hr>
<ul>
<li><p>perceptron은 입력값 x에 대해 weight를 곱하고 bias를 더한 후 activation function을 거쳐서 나온 output을 통해 두가지의 class를 가지는 AND, OR 문제를 해결하기 위해 고안되었습니다.</p>
</li>
<li><p>AND gate는 다음과 같이 표로 나타낼 수 있습니다.</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>Output</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<ul>
<li><p>위의 표는 매우 익숙하지만 이를 그래프로 나타내면 다음과 같이도 나타낼 수 있습니다.</p>
</li>
<li><p><img src="https://www.simonho.ca/wp-content/uploads/2018/02/AND_gate.png" alt="AND gate"></p>
</li>
<li><p>위의 그래프에서 0과 1을(off와 on)을 선 하나를 통해서 구분할 수 있는 방법은 빨간 점선으로 표시되어 있습니다. 즉, 하나의 선으로 두 가지의 class를 구분할 수 있습니다.</p>
</li>
<li><p>OR gate도 마찬가지 입니다.</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>Output</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<ul>
<li><p>위와 같은 OR gate표를 그래프로 나타내면 다음과 같습니다.</p>
</li>
<li><p><img src="https://www.simonho.ca/wp-content/uploads/2018/02/OR_gate.png" alt="OR gate"></p>
</li>
<li><p>OR gate 그래프에서도 0과 1(off와 on)을 하나의 선으로 구분할 수 있습니다. 즉, AND gate와 마찬가지로 하나의 선으로 두 가지의 class를 구분할 수 있다는 뜻입니다.</p>
</li>
<li><p>다시 말해, AND 와 OR gate는 하나의 Layer를 가지는 perceptron으로 구분이 가능했습니다. </p>
</li>
<li><p>하지만, XOR gate는 달랐습니다.</p>
</li>
<li><p>XOR gate를 표로 나타내면 다음과 같습니다.</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>Output</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody></table>
<ul>
<li><p>이와같이 입력이 같으면 0을 다르면 1을 되돌려주는 XOR gate를 그래프로 나타내면 다음과 같습니다.</p>
</li>
<li><p><img src="https://www.simonho.ca/wp-content/uploads/2018/02/XOR_gate.png" alt="XOR gate"></p>
</li>
<li><p>위와 같은 그래프에서 0과 1(off와 on)을 하나의 선으로 구분할 수 없었습니다. 즉, 하나의 perceptron으로는 AND/OR gate 문제는 해결할 수 있었지만 XOR gate 문제를 해결할 수 없었습니다.</p>
</li>
<li><p>이렇게 하나의 perceptron으로 해결할 수 없는 문제를 해결하기 위해 등장한것이 Multi Layer Perceptron입니다.</p>
</li>
<li><p>다시 한번 위의 그래프를 봤을때, 하나의 선이 아니라 두개의 선으로는 0과 1(off와 on)을 구분할 수 있을까요?</p>
</li>
<li><p>답은 YES입니다. 즉, 두개 이상의 perceptron으로는 XOR gate문제를 해결할 수 있었습니다.</p>
</li>
<li><p>4개의 Layer를 갖는 모델을 구현해 확인해 보겠습니다.</p>
</li>
<li><p>먼저 XOR gate에 해당하는 데이터를 만들고,</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># XOR 데이터</span></span><br><span class="line">X = torch.FloatTensor([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]).to(device)</span><br><span class="line">Y = torch.FloatTensor([[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">1</span>], [<span class="number">0</span>]]).to(device)</span><br></pre></td></tr></table></figure>

<ul>
<li>4개의 layer를 생성해 모델을 정의해줍니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4개의 레이어가 있는 MLP(Multi Layer Perceptron)</span></span><br><span class="line">linear1 = torch.nn.Linear(<span class="number">2</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear2 = torch.nn.Linear(<span class="number">10</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear3 = torch.nn.Linear(<span class="number">10</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear4 = torch.nn.Linear(<span class="number">10</span>, <span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 정의</span></span><br><span class="line">model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid,</span><br><span class="line">                            linear4, sigmoid).to(device)</span><br></pre></td></tr></table></figure>

<ul>
<li>이후 loss와 optimizer를 정의해주고,</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  loss / optimizer 정의</span></span><br><span class="line">criterion = torch.nn.BCELoss().to(device)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>모델을 통해 weight와 bias를 학습합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 학습</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10001</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    hypothesis = model(X)</span><br><span class="line"></span><br><span class="line">    loss = criterion(hypothesis, Y)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        print(epoch, loss.item())</span><br><span class="line"><span class="comment">#&gt;&gt;&gt; print</span></span><br><span class="line"><span class="number">0</span> <span class="number">0.6948983669281006</span></span><br><span class="line"><span class="number">100</span> <span class="number">0.6931558847427368</span></span><br><span class="line"><span class="number">200</span> <span class="number">0.6931535005569458</span></span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line"><span class="number">9800</span> <span class="number">0.00016415018762927502</span></span><br><span class="line"><span class="number">9900</span> <span class="number">0.00016021561168599874</span></span><br><span class="line"><span class="number">10000</span> <span class="number">0.0001565046259202063</span></span><br></pre></td></tr></table></figure>

<ul>
<li>학습이 끝나면 실제값과 예측값이 잘 맞아 떨어지는지 확인합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 학습 후 실제값과 예측값 비교해보기</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    hypothesis = model(X)</span><br><span class="line">    predict = (hypothesis &gt; <span class="number">0.5</span>).float()</span><br><span class="line">    accuracy = (predict == Y).float().mean()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Hyptthesis : '</span>, hypothesis.detach().cpu().numpy(),</span><br><span class="line">          <span class="string">'\nCorrect : '</span>,predict.detach().cpu().numpy(),</span><br><span class="line">          <span class="string">'\nAccuracy : '</span>,accuracy.item())</span><br><span class="line"><span class="comment">#&gt;&gt;&gt; print</span></span><br><span class="line">Hyptthesis :  [[<span class="number">1.1168354e-04</span>]</span><br><span class="line"> [<span class="number">9.9982882e-01</span>]</span><br><span class="line"> [<span class="number">9.9984241e-01</span>]</span><br><span class="line"> [<span class="number">1.8533420e-04</span>]] </span><br><span class="line">Correct :  [[<span class="number">0.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span>]] </span><br><span class="line">Accuracy :  <span class="number">1.0</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>위의 결과를 통해 Multi Layer Perceptron을 사용하면 XOR gate문제를 해결할 수 있음을 확인했습니다.</p>
</li>
<li><p><a href="https://www.simonho.ca/machine-learning/xor-logic-gate-neural-networks/">참고</a></p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/perceptron_XOR_problem.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>









    
<div class="card card-transparent">
    <nav class="pagination is-centered" role="navigation" aria-label="pagination">
        <div class="pagination-previous is-invisible is-hidden-mobile">
            <a class="is-flex-grow has-text-black-ter" href="/tags/Python/page/0/">Previous</a>
        </div>
        <div class="pagination-next">
            <a class="is-flex-grow has-text-black-ter" href="/tags/Python/page/2/">Next</a>
        </div>
        <ul class="pagination-list is-hidden-mobile">
            
            <li><a class="pagination-link is-current" href="/tags/Python/">1</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/tags/Python/page/2/">2</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/tags/Python/page/3/">3</a></li>
            
        </ul>
    </nav>
</div>
</div>
                




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="" src="/images/avatar.png" alt="Already-Ready">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        Already-Ready
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        I&#39;m Going Now
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Seongnam city</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Posts
                    </p>
                    <a href="/archives">
                        <p class="title has-text-weight-normal">
                            42
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Categories
                    </p>
                    <a href="/categories">
                        <p class="title has-text-weight-normal">
                            12
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Tags
                    </p>
                    <a href="/tags">
                        <p class="title has-text-weight-normal">
                            8
                        </p>
                    </a>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">
                Follow</a>
        </div>
        
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Github" href="https://github.com/Already-Ready">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Facebook" href="https://facebook.com">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Twitter" href="https://twitter.com">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Dribbble" href="https://dribbble.com">
                
                <i class="fab fa-dribbble"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Links
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://github.com/Already-Ready" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">My_Github</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">github.com</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/CS-basic/">
            <span class="level-start">
                <span class="level-item">CS basic</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">6</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/CS-basic/CtCI/">
            <span class="level-start">
                <span class="level-item">CtCI</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Go/">
            <span class="level-start">
                <span class="level-item">Go</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Go/About-Go/">
            <span class="level-start">
                <span class="level-item">About Go</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Go/tutorial/">
            <span class="level-start">
                <span class="level-item">tutorial</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Python/">
            <span class="level-start">
                <span class="level-item">Python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">17</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Python/About-Python/">
            <span class="level-start">
                <span class="level-item">About Python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Python/Pytorch/">
            <span class="level-start">
                <span class="level-item">Pytorch</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">13</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/baekjoon/">
            <span class="level-start">
                <span class="level-item">baekjoon</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">11</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/baekjoon/Go/">
            <span class="level-start">
                <span class="level-item">Go</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/baekjoon/python/">
            <span class="level-start">
                <span class="level-item">python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">11</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/github-io/">
            <span class="level-start">
                <span class="level-item">github.io</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/CS/" style="font-size: 14px;">CS</a> <a href="/tags/CtCI/" style="font-size: 12px;">CtCI</a> <a href="/tags/Go/" style="font-size: 16px;">Go</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/Pytorch/" style="font-size: 18px;">Pytorch</a> <a href="/tags/baekjoon/" style="font-size: 16px;">baekjoon</a> <a href="/tags/github-io/" style="font-size: 10px;">github.io</a> <a href="/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/" style="font-size: 10px;">블로그</a>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
            <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2020/05/06/Pytorch-visdom%EC%9C%BC%EB%A1%9C-Loss-plot%EA%B7%B8%EB%A6%AC%EA%B8%B0/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_visdom으로_Loss_plot그리기">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-06T16:14:42.000Z">2020-05-06</time></div>
                    <a href="/2020/05/06/Pytorch-visdom%EC%9C%BC%EB%A1%9C-Loss-plot%EA%B7%B8%EB%A6%AC%EA%B8%B0/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_visdom으로_Loss_plot그리기</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/01/Pytorch-MNIST-CNN/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_MNIST_CNN">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-01T21:01:13.000Z">2020-05-01</time></div>
                    <a href="/2020/05/01/Pytorch-MNIST-CNN/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_MNIST_CNN</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/04/30/Pytorch-Convolution-layer/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_Convolution_layer">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-04-30T16:41:25.000Z">2020-04-30</time></div>
                    <a href="/2020/04/30/Pytorch-Convolution-layer/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_Convolution_layer</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/04/25/%ED%8C%8C%EC%9D%B4%EC%8D%AC-visdom-port-%EB%B3%80%EA%B2%BD%ED%95%98%EA%B8%B0/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="파이썬_visdom_port_변경하기">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-04-25T23:14:37.000Z">2020-04-25</time></div>
                    <a href="/2020/04/25/%ED%8C%8C%EC%9D%B4%EC%8D%AC-visdom-port-%EB%B3%80%EA%B2%BD%ED%95%98%EA%B8%B0/" class="title has-link-black-ter is-size-6 has-text-weight-normal">파이썬_visdom_port_변경하기</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/About-Python/">About Python</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/04/21/Pytorch-Batch-Normalization/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_Batch_Normalization">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-04-21T21:01:37.000Z">2020-04-21</time></div>
                    <a href="/2020/04/21/Pytorch-Batch-Normalization/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_Batch_Normalization</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2020/05/">
                <span class="level-start">
                    <span class="level-item">May 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">April 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">12</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">March 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/02/">
                <span class="level-start">
                    <span class="level-item">February 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/01/">
                <span class="level-start">
                    <span class="level-item">January 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">17</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/12/">
                <span class="level-start">
                    <span class="level-item">December 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CS/">
                        <span class="tag">CS</span>
                        <span class="tag is-grey">6</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CtCI/">
                        <span class="tag">CtCI</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Go/">
                        <span class="tag">Go</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Python/">
                        <span class="tag">Python</span>
                        <span class="tag is-grey">26</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Pytorch/">
                        <span class="tag">Pytorch</span>
                        <span class="tag is-grey">13</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/baekjoon/">
                        <span class="tag">baekjoon</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/github-io/">
                        <span class="tag">github.io</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/">
                        <span class="tag">블로그</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
        
        </div>
    
</div>

                




<div class="column is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only has-order-3 column-right ">
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2020/05/06/Pytorch-visdom%EC%9C%BC%EB%A1%9C-Loss-plot%EA%B7%B8%EB%A6%AC%EA%B8%B0/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_visdom으로_Loss_plot그리기">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-06T16:14:42.000Z">2020-05-06</time></div>
                    <a href="/2020/05/06/Pytorch-visdom%EC%9C%BC%EB%A1%9C-Loss-plot%EA%B7%B8%EB%A6%AC%EA%B8%B0/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_visdom으로_Loss_plot그리기</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/01/Pytorch-MNIST-CNN/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_MNIST_CNN">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-01T21:01:13.000Z">2020-05-01</time></div>
                    <a href="/2020/05/01/Pytorch-MNIST-CNN/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_MNIST_CNN</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/04/30/Pytorch-Convolution-layer/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_Convolution_layer">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-04-30T16:41:25.000Z">2020-04-30</time></div>
                    <a href="/2020/04/30/Pytorch-Convolution-layer/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_Convolution_layer</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/04/25/%ED%8C%8C%EC%9D%B4%EC%8D%AC-visdom-port-%EB%B3%80%EA%B2%BD%ED%95%98%EA%B8%B0/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="파이썬_visdom_port_변경하기">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-04-25T23:14:37.000Z">2020-04-25</time></div>
                    <a href="/2020/04/25/%ED%8C%8C%EC%9D%B4%EC%8D%AC-visdom-port-%EB%B3%80%EA%B2%BD%ED%95%98%EA%B8%B0/" class="title has-link-black-ter is-size-6 has-text-weight-normal">파이썬_visdom_port_변경하기</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/About-Python/">About Python</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/04/21/Pytorch-Batch-Normalization/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_Batch_Normalization">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-04-21T21:01:37.000Z">2020-04-21</time></div>
                    <a href="/2020/04/21/Pytorch-Batch-Normalization/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_Batch_Normalization</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2020/05/">
                <span class="level-start">
                    <span class="level-item">May 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">April 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">12</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">March 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/02/">
                <span class="level-start">
                    <span class="level-item">February 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/01/">
                <span class="level-start">
                    <span class="level-item">January 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">17</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/12/">
                <span class="level-start">
                    <span class="level-item">December 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CS/">
                        <span class="tag">CS</span>
                        <span class="tag is-grey">6</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CtCI/">
                        <span class="tag">CtCI</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Go/">
                        <span class="tag">Go</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Python/">
                        <span class="tag">Python</span>
                        <span class="tag is-grey">26</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Pytorch/">
                        <span class="tag">Pytorch</span>
                        <span class="tag is-grey">13</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/baekjoon/">
                        <span class="tag">baekjoon</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/github-io/">
                        <span class="tag">github.io</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/">
                        <span class="tag">블로그</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="Hexo" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2020 John Doe&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'http://yoursite.com',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>














<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>