<!DOCTYPE html>
<html  lang="en">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>Tag: Python - Hexo</title>


    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/tags/Python/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/images/og_image.png">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/images/og_image.png">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    
    
    
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    
    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="Hexo" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="/tags">Tags</a>
                
                <a class="navbar-item"
                href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-6-widescreen has-order-2 column-main"><div class="card">
    <div class="card-content">
        <nav class="breadcrumb" aria-label="breadcrumbs">
        <ul>
            <li><a href="/tags">Tags</a></li>
            <li class="is-active"><a href="#" aria-current="page">Python</a></li>
        </ul>
        </nav>
    </div>
</div>

    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-18T22:57:35.000Z">2020-04-18</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    7 minutes read (About 1108 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/18/Pytorch-Dropout/">Pytorch_Dropout</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Dropout에-대하여"><a href="#Pytorch-Dropout에-대하여" class="headerlink" title="Pytorch Dropout에 대하여"></a>Pytorch Dropout에 대하여</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>Dropout은 모델의 layer가 많아질때 생기는 overfitting문제를 해결하기 위해 사용된다.  </p>
</li>
<li><p>overfitting이란 train데이터를 모델이 지나치게 정확히 학습하는 바람에 모델이 test데이터에서는 좋은 결과를 내놓지 못하는 경우이다.  </p>
</li>
<li><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Overfitting.svg/300px-Overfitting.svg.png" alt="overfitting">  </p>
</li>
<li><p>위 그림에서 초록색선을 보면 빨간점과 파란점을 완벽하게 분류하는 것을 확인할 수 있다. 이렇게 train 데이터에 지나치게 학습된 경우를 overfitting이라하며, 적절한 학습의 정도를 까만선이 나타내고 있다.  </p>
</li>
<li><p>이러한 overfitting문제를 해결하기 위해 dropout을 사용하게 된다.  </p>
</li>
<li><p>dropout이란 forward함수를 통해 train데이터가 layer를 지날때 뉴런 일부를 생략하고 학습을 진행하는것이다.  </p>
</li>
<li><p><img src="https://miro.medium.com/max/1400/1*iWQzxhVlvadk6VAJjsgXgg.png" alt="dropout">  </p>
</li>
<li><p>위의 우측 그림과 같이 layer마다 임의의 뉴런을 생략하고 학습을 진행하는 것을 볼 수 있다.  </p>
</li>
<li><p>사용자가 정의한 비율만큼의 뉴런을 생략하고 학습을 진행할 때, 매 epoch마다 다른 뉴런들이 꺼졌다가 켜지기를 반복하게 된다.  </p>
</li>
<li><p>이는 매번 다른 모델을 학습하는것과 유사하기 때문에 Ensemble(앙상블)효과를 기대할 수도 있다.  </p>
</li>
<li><p>dropout을 사용할 때는 non-linear 활성화 함수 다음에 사용하게 된다.  </p>
</li>
<li><p>MNIST 데이터셋을 이용해 활용법을 살펴보자.  </p>
</li>
<li><p>통과할 linear 와 relu 그리고 dropout을 설정해준다.  </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nn Linear layer / relu / dropout 만들기</span></span><br><span class="line">linear1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">512</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear2 = torch.nn.Linear(<span class="number">512</span>, <span class="number">512</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear3 = torch.nn.Linear(<span class="number">512</span>, <span class="number">512</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear4 = torch.nn.Linear(<span class="number">512</span>, <span class="number">512</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear5 = torch.nn.Linear(<span class="number">512</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">relu = torch.nn.ReLU()</span><br><span class="line">dropout = torch.nn.Dropout(p=drop_prob) <span class="comment"># drop_prob = 0.3 in my code</span></span><br></pre></td></tr></table></figure>

<ul>
<li>이를 이용해 모델을 만들때 선형함수를 통과하고 활성화 함수를 지난 뒤에 dropout을 적용해준다.  </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = torch.nn.Sequential(linear1, relu, dropout, linear2, relu, dropout,</span><br><span class="line">                            linear3, relu, dropout, linear4, relu, dropout,</span><br><span class="line">                            linear5).to(device)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>이렇게 만들어진 모델로 학습과 평가를 똑같이 진행할 수 없다.  </p>
</li>
<li><p>왜냐하면 학습 이후 평가할 때 dropout이 켜져있다면 모든 weight를 사용하지 않고 output을 내게 되기 때문이다.  </p>
</li>
<li><p>이렇게 dropout은 학습할때는 사용하고, 평가를 위해서는 사용하지 말아야한다.  </p>
</li>
<li><p>이를 조절할 수 있는 함수가 <code>train()</code>함수와 <code>eval()</code>함수이다.  </p>
</li>
<li><p>다음고 같이 <code>train()</code>함수를 통해 dropout을 사용하겠다는 표시를 한 후, 학습을 진행해야 한다.  </p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">model.train() <span class="comment"># train() 함수를 사용하면 dropout=True로 설정된다.</span></span><br><span class="line"><span class="comment"># 즉 학습할때 사용해야하고 추후 모델을 평가할때는 eval()함수를 꼭 설정해줘야한다.</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    avg_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, Y <span class="keyword">in</span> data_loader:</span><br><span class="line">        X = X.view(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        Y = Y.to(device)</span><br><span class="line"></span><br><span class="line">        hypothesis = model(X)</span><br><span class="line">        loss = criterion(hypothesis, Y)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        avg_loss += loss / total_batch</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Epoch:'</span>, <span class="string">'%04d'</span> % (epoch + <span class="number">1</span>), <span class="string">'cost ='</span>, <span class="string">'&#123;:.9f&#125;'</span>.format(avg_loss))</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Learning finished'</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>학습을 마친 후, 랜덤한 하나의 데이터를 통해 결과를 확인해 보고 싶다면 다음과 같이 <code>eval()</code>함수를 통해 dropout을 사용하지 않겠다고 표시한 후 평가를 진행해야 한다.  </li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad(): <span class="comment"># --&gt; 여기에서는(test에서는) gradient를 계산하지 않고 진행한다는 뜻이다.</span></span><br><span class="line">    model.eval() <span class="comment"># --&gt; eval() 함수를 사용하면 dropout=False 로 설정되서 모든 노드를 사용해 모델을 평가하게된다.</span></span><br><span class="line">    X_test = mnist_test.test_data.view(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>).float().to(device)</span><br><span class="line">    Y_test = mnist_test.test_labels.to(device)</span><br><span class="line"></span><br><span class="line">    prediction = model(X_test)</span><br><span class="line">    correct_prediction = torch.argmax(prediction, dim=<span class="number">1</span>) == Y_test</span><br><span class="line">    accuracy = correct_prediction.float().mean()</span><br><span class="line">    print(<span class="string">'Accuracy:'</span>, accuracy.item())</span><br><span class="line"></span><br><span class="line">    r = random.randint(<span class="number">0</span>, len(mnist_test) - <span class="number">1</span>)</span><br><span class="line">    X_single_data = mnist_test.test_data[r:r + <span class="number">1</span>].view(<span class="number">-1</span>, <span class="number">28</span> * <span class="number">28</span>).float().to(device)</span><br><span class="line">    Y_single_data = mnist_test.test_labels[r:r + <span class="number">1</span>].to(device)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Label: '</span>, Y_single_data.item())</span><br><span class="line">    single_prediction = model(X_single_data)</span><br><span class="line">    print(<span class="string">'Prediction: '</span>, torch.argmax(single_prediction, <span class="number">1</span>).item())</span><br></pre></td></tr></table></figure>

<ul>
<li><p>첫째로, dropout은 non-linear 활성화 함수 다음에 사용한다는 점</p>
</li>
<li><p>둘째로, 학습과 평가를 위해서는 <code>train()</code>함수와 <code>eval()</code>함수를 반드시 사용해야 된다는 것을 기억해야겠다.</p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/dropout_MNIST.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-16T19:56:28.000Z">2020-04-16</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 624 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/16/Pytorch-weight-initialization/">Pytorch_weight_initialization</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Weight-initialization에-대하여"><a href="#Pytorch-Weight-initialization에-대하여" class="headerlink" title="Pytorch Weight initialization에 대하여"></a>Pytorch Weight initialization에 대하여</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>모델을 학습하기 이전에 weight의 초기값을 설정하는 문제는 모델의 학습에 굉장히 중요한 문제였습니다.</p>
</li>
<li><p>초기에 이 문제를 해결하기 위해서 사용했던 방법은 RBM(restricted boltzmann machine)이었습니다.</p>
</li>
<li><p>RBM은 layer1과 다음 레이어 layer2를 통해 weight1을 학습한 후 w1을 고정한 상태에서 layer2와 layer3를 통해 weight2를 학습하는 과정을 반복하는 방법입니다.</p>
</li>
<li><p><img src="http://www.todaysoftmag.ro/tsm/images/articles/tsm20/a22.png" alt="RBM"></p>
</li>
<li><p>하지만, 요즘에는 새로운 initialization 방법들이 제안되면서 RBM을 많이 사용하지 않고 있습니다.</p>
</li>
<li><p>대표적으로 간단히 initialization할 수 있는 두 가지 방법인 Xavier / He initialization 에 대해 알아보겠습니다.</p>
</li>
<li><p><a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_"><strong>Xavier initialization</strong></a></p>
<ul>
<li><p>Xavier / He initialization 모두 Normal initialization 방법과 Uniform initialization 방법을 가지고 있으며 모두 간단한 수식을 통해 이루어집니다.</p>
</li>
<li><p>Xavier Normal initialization</p>
<script type="math/tex; mode=display">W\sim N({ 0 }, Var(W))</script>

<script type="math/tex; mode=display">Var(W)=\sqrt{\frac { 2 }{ { n }_{ in }+{ n }_{ out } } }</script>
</li>
<li><p>n<sub>in</sub>은 layer의 input수, n<sub>out</sub>은 layer의 output수를 뜻합니다.<br><br></br></p>
</li>
<li><p>Xavier Uniform initialization</p>
<script type="math/tex; mode=display">W\sim U(- \sqrt{\frac { 6 }{ { n }_{ in }+{ n }_{ out } } } , \space\space + \sqrt{\frac { 6 }{ { n }_{ in }+{ n }_{ out } } } )</script>
</li>
<li><p>n<sub>in</sub>은 layer의 input수, n<sub>out</sub>은 layer의 output수를 뜻합니다.<br><br></br></p>
</li>
</ul>
</li>
<li><p><a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_"><strong>He initialization</strong></a></p>
<ul>
<li><p>He Normal initialization</p>
<script type="math/tex; mode=display">W\sim N({ 0 }, Var(W))</script>

<script type="math/tex; mode=display">Var(W)=\sqrt{\frac { 2 }{ { n }_{ in } } }</script> 
</li>
<li><p>n<sub>in</sub>은 layer의 input수를 뜻합니다.<br><br></br></p>
</li>
<li><p>He Uniform initialization</p>
<script type="math/tex; mode=display">W\sim U(- \sqrt{\frac { 6 }{ { n }_{ in } } } , \space\space + \sqrt{\frac { 6 }{ { n }_{ in } } } )</script>
</li>
<li><p>n<sub>in</sub>은 layer의 input수를 뜻합니다.  </p>
</li>
</ul>
</li>
<li><p>Pytorch에서는 <code>torch.nn.init</code>패키지를 통해서 사용할 수 있습니다.</p>
</li>
<li><p><a href="https://already-ready.github.io/2020/04/14/Pytorch-ReLU/">ReLU</a>에 관해서 작성한 포스트에서 작성한 코드와 달라진 점은 weight를 초기화해주는 부분뿐입니다.</p>
</li>
<li><p>먼저 linear layer를 만들고,</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">linear1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear2 = torch.nn.Linear(<span class="number">256</span>, <span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear3 = torch.nn.Linear(<span class="number">256</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">relu = torch.nn.ReLU()</span><br></pre></td></tr></table></figure>

<ul>
<li>다음과 같이 xavier_uniform으로 초기화 할 수 있습니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.init.xavier_uniform_(linear1.weight)</span><br><span class="line">torch.nn.init.xavier_uniform_(linear2.weight)</span><br><span class="line">torch.nn.init.xavier_uniform_(linear3.weight)</span><br></pre></td></tr></table></figure>

<ul>
<li><a href="https://already-ready.github.io/2020/04/14/Pytorch-ReLU/">ReLU</a> 포스트의 코드와 다른점은 weight initialization뿐이지만 Accuracy가 상승된것을 확인할 수 있습니다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/xavier_initialization_MNIST.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-14T16:26:50.000Z">2020-04-14</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    6 minutes read (About 930 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/14/Pytorch-ReLU/">Pytorch_ReLU</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-ReLU에-대하여"><a href="#Pytorch-ReLU에-대하여" class="headerlink" title="Pytorch ReLU에 대하여"></a>Pytorch ReLU에 대하여</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p><a href="https://already-ready.github.io/2020/04/08/Pytorch-Logistic-regression/">이전 포스팅</a>에서 두 가지 클래스를 분류하는 모델을 만들때 sigmoid함수를 사용했습니다.</p>
</li>
<li><p>하지만, sigmoid함수에는 모델이 깊어질수록 vanishing Gradient문제가 발생하게 됩니다.</p>
</li>
<li><p>vanishing Gradient란, 역전파를 통해 gradient를 전파받을 때, 0에 근접한 값들이 곱해짐에 따라 앞단으로 갈수록 gradient가 사라지게 되는 문제입니다.</p>
</li>
<li><p>이러한 문제가 생기는 이유는 sigmoid 함수 그래프를 통해 확인할 수 있습니다.</p>
</li>
<li><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png" alt="sigmoid 그래프"></p>
</li>
<li><p>sigmoid 그래프의 양 극단으로 갈수록 기울기는 0에 수렴하게 되는것을 볼 수 있고, 이때문에 역전파를 통해 gradient가 곱해질 때마다 그 값 또한 0으로 수렴하게 됩니다.</p>
</li>
<li><p>따라서 아래 그림과 같이 역전파가 깊이 전달될수록 gradient가 사라지는 vanishing gradient 문제가 발생하게 됩니다.</p>
</li>
<li><p><img src="https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F278186%2Fd158ec3585bc1551d9f3a03ae13a3a73%2Fvanishing%20gradient%20problem.png?generation=1574233763365617&alt=media" alt="vanishing Gradient"></p>
</li>
<li><p>이러한 문제를 해결하기 위해 Hinton교수님이 찾아낸 방법이 바로 ReLU 입니다.</p>
</li>
<li><p>ReLU를 수식으로 나타내면 다음과 같습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f(x) = max(<span class="number">0</span>, x)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>입력값 x가 들어왔을때, 0보다 크다면 자기자신을 그렇지 않다면 0을 되돌려주는것이 바로 ReLU입니다.</p>
</li>
<li><p>코드에서 활성화 함수만 sigmoid에서 ReLU로 바꾸면 되기때문에 ReLU를 이용한 MNIST classifier 를 만들어보겠습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># nn Linear layer 만들기</span></span><br><span class="line">linear1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear2 = torch.nn.Linear(<span class="number">256</span>, <span class="number">256</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear3 = torch.nn.Linear(<span class="number">256</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">relu = torch.nn.ReLU()</span><br></pre></td></tr></table></figure>

<ul>
<li>Linear layer와 활성화 함수로 사용할 ReLU를 정의해주고, Linear layer의 weight를 normalization 합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Linear layer의 weight를 normalization시켜주기</span></span><br><span class="line">torch.nn.init.normal_(linear1.weight)</span><br><span class="line">torch.nn.init.normal_(linear2.weight)</span><br><span class="line">torch.nn.init.normal_(linear3.weight)</span><br></pre></td></tr></table></figure>

<ul>
<li>위를 이용해 모델을 정의하고,</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델 정의</span></span><br><span class="line">model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)</span><br><span class="line"><span class="comment">###&gt;&gt;&gt; 왜 linear3다음에는 relu를 하지않는가</span></span><br><span class="line"><span class="comment">###&gt;&gt;&gt; 우리가 사용할 criterion은 CrossEntropyLoss인데 여기에는 마지막에 softmax activation이 포함되어 있기 때문이다.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>loss / optimizer 를 정의합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># loss / optimizer 정의</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss().to(device)</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br></pre></td></tr></table></figure>

<ul>
<li>정한 epoch수만큼 모델을 학습시킵니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">total_batch = len(data_loader)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    avg_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> X, Y <span class="keyword">in</span> data_loader:</span><br><span class="line">        X = X.view(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>).to(device)</span><br><span class="line">        Y = Y.to(device)</span><br><span class="line"></span><br><span class="line">        hypothesis = model(X)</span><br><span class="line">        loss = criterion(hypothesis, Y)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        avg_loss += loss / total_batch</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Epoch:'</span>, <span class="string">'%04d'</span> % (epoch + <span class="number">1</span>), <span class="string">'cost ='</span>, <span class="string">'&#123;:.9f&#125;'</span>.format(avg_loss))</span><br></pre></td></tr></table></figure>

<ul>
<li>학습이 끝났다면 테스트 데이터에서 하나를 선택해 예측값과 실제값을 비교해 결과를 확인해봅니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad(): <span class="comment"># --&gt; 여기에서는(test에서는) gradient를 계산하지 않고 진행한다는 뜻이다.</span></span><br><span class="line">    X_test = mnist_test.test_data.view(<span class="number">-1</span>, <span class="number">28</span>*<span class="number">28</span>).float().to(device)</span><br><span class="line">    Y_test = mnist_test.test_labels.to(device)</span><br><span class="line"></span><br><span class="line">    prediction = model(X_test)</span><br><span class="line">    correct_prediction = torch.argmax(prediction, dim=<span class="number">1</span>) == Y_test</span><br><span class="line">    accuracy = correct_prediction.float().mean()</span><br><span class="line">    print(<span class="string">'Accuracy:'</span>, accuracy.item())</span><br><span class="line"></span><br><span class="line">    r = random.randint(<span class="number">0</span>, len(mnist_test) - <span class="number">1</span>)</span><br><span class="line">    X_single_data = mnist_test.test_data[r:r + <span class="number">1</span>].view(<span class="number">-1</span>, <span class="number">28</span> * <span class="number">28</span>).float().to(device)</span><br><span class="line">    Y_single_data = mnist_test.test_labels[r:r + <span class="number">1</span>].to(device)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Label: '</span>, Y_single_data.item())</span><br><span class="line">    single_prediction = model(X_single_data)</span><br><span class="line">    print(<span class="string">'Prediction: '</span>, torch.argmax(single_prediction, <span class="number">1</span>).item())</span><br></pre></td></tr></table></figure>

<ul>
<li>하나의 데이터를 통해 예측값과 실제값까지 확인해볼 수 있었습니다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/MNIST_nn_ReLU.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-13T15:45:13.000Z">2020-04-13</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 593 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/13/Pytorch-Softmax-classification/">Pytorch_Softmax_classification</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Softmax-Classificaton-을-통한-N개의-이벤트-분류하기"><a href="#Pytorch-Softmax-Classificaton-을-통한-N개의-이벤트-분류하기" class="headerlink" title="Pytorch Softmax Classificaton 을 통한 N개의 이벤트 분류하기"></a>Pytorch Softmax Classificaton 을 통한 N개의 이벤트 분류하기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p><a href="https://already-ready.github.io/2020/04/08/Pytorch-Logistic-regression/">binary classificaton</a> 문제를 해결할 때 sigmoid함수를 사용했습니다.</p>
</li>
<li><p>정확히는 <code>F.binary_cross_entropy</code> 안에 sigmoid함수가 같이 녹아있는 형태로 loss함수를 사용했습니다.</p>
</li>
<li><p>하지만, 세개 이상의 분류문제를 해결하기 위해서는 <code>sigmoid</code>함수가 아닌 <code>softmax</code>함수를 사용해야 합니다.</p>
</li>
<li><p>softmax함수는 아래와 같은 식으로 나타낼 수 있습니다.</p>
</li>
<li><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bdc1f8eaa8064d15893f1ba6426f20ff8e7149c5" alt="softmax"></p>
</li>
<li><p>K개의 입력값을 0~1 사이의 값이 되도록 K개의 SUM으로 나눠주게 됩니다. 따라서 모든 확률의 합은 1이됩니다. 또한 입력값의 순서가 출력값의 순서와 같음을 확인할 수 있습니다.</p>
</li>
<li><p>이제 Pytorch를 통해 SoftmaxClassifierModel을 정의해 보았습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델 정의</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftmaxClassifierModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="number">16</span>, <span class="number">7</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.linear(x)</span><br><span class="line"></span><br><span class="line">model = SoftmaxClassifierModel()</span><br></pre></td></tr></table></figure>

<ul>
<li><p>모델을 정의한 내용을 보면 입력값X에 따른 Linear함수만을 통과하고 Softmax함수를 통과하지 않는것을 볼 수 있습니다.</p>
</li>
<li><p>이는 loss함수에서 사용하게 될 <code>F.cross_entropy</code>에 Softmax함수가 포함되어 있기 때문입니다.</p>
</li>
<li><p>따라서 정의한 모델에서는 Softmax를 통과하기전의 Linear함수를 통과한 output값을 되돌려줘야 합니다.</p>
</li>
<li><p>optimizer를 정의하고,</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># optimizer 정의</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>정한 epoch수 만큼 학습하며 loss를 출력해봅니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 학습</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs + <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">    predict = model(x_train)</span><br><span class="line">    loss = F.cross_entropy(predict, y_train)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Epoch &#123;:4d&#125;/&#123;&#125; loss : &#123;:.6f&#125;'</span>.format(</span><br><span class="line">            epoch, epochs, loss.item()</span><br><span class="line">        ))</span><br><span class="line">		</span><br><span class="line"><span class="comment">###&gt;&gt;&gt;print</span></span><br><span class="line">Epoch    <span class="number">0</span>/<span class="number">1000</span> loss : <span class="number">1.721660</span></span><br><span class="line">Epoch  <span class="number">100</span>/<span class="number">1000</span> loss : <span class="number">0.462462</span></span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">Epoch  <span class="number">900</span>/<span class="number">1000</span> loss : <span class="number">0.110220</span></span><br><span class="line">Epoch <span class="number">1000</span>/<span class="number">1000</span> loss : <span class="number">0.100880</span></span><br></pre></td></tr></table></figure>

<ul>
<li>출력된 loss를 통해 모델이 정상적으로 학습되는것을 확인할 수 있습니다. 이처럼 N개의 이벤트를 분류할 경우는 Softmax함수를 두개의 이벤트를 분류할 경우는 Sigmoid함수를 사용한다는것을 배울 수 있었습니다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/softmax_classification.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-10T01:20:19.000Z">2020-04-10</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    6 minutes read (About 961 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/10/Pytorch-Multi-Layer-Perceptron-MLP/">Pytorch_Multi_Layer_Perceptron_MLP</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Multi-Layer-Perceptron-MLP-에-관하여-with-code"><a href="#Pytorch-Multi-Layer-Perceptron-MLP-에-관하여-with-code" class="headerlink" title="Pytorch Multi Layer Perceptron(MLP)에 관하여 with code"></a>Pytorch Multi Layer Perceptron(MLP)에 관하여 with code</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><hr>
<ul>
<li><p>perceptron은 입력값 x에 대해 weight를 곱하고 bias를 더한 후 activation function을 거쳐서 나온 output을 통해 두가지의 class를 가지는 AND, OR 문제를 해결하기 위해 고안되었습니다.</p>
</li>
<li><p>AND gate는 다음과 같이 표로 나타낼 수 있습니다.</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>Output</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<ul>
<li><p>위의 표는 매우 익숙하지만 이를 그래프로 나타내면 다음과 같이도 나타낼 수 있습니다.</p>
</li>
<li><p><img src="https://www.simonho.ca/wp-content/uploads/2018/02/AND_gate.png" alt="AND gate"></p>
</li>
<li><p>위의 그래프에서 0과 1을(off와 on)을 선 하나를 통해서 구분할 수 있는 방법은 빨간 점선으로 표시되어 있습니다. 즉, 하나의 선으로 두 가지의 class를 구분할 수 있습니다.</p>
</li>
<li><p>OR gate도 마찬가지 입니다.</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>Output</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody></table>
<ul>
<li><p>위와 같은 OR gate표를 그래프로 나타내면 다음과 같습니다.</p>
</li>
<li><p><img src="https://www.simonho.ca/wp-content/uploads/2018/02/OR_gate.png" alt="OR gate"></p>
</li>
<li><p>OR gate 그래프에서도 0과 1(off와 on)을 하나의 선으로 구분할 수 있습니다. 즉, AND gate와 마찬가지로 하나의 선으로 두 가지의 class를 구분할 수 있다는 뜻입니다.</p>
</li>
<li><p>다시 말해, AND 와 OR gate는 하나의 Layer를 가지는 perceptron으로 구분이 가능했습니다. </p>
</li>
<li><p>하지만, XOR gate는 달랐습니다.</p>
</li>
<li><p>XOR gate를 표로 나타내면 다음과 같습니다.</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
<th>Output</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
</tbody></table>
<ul>
<li><p>이와같이 입력이 같으면 0을 다르면 1을 되돌려주는 XOR gate를 그래프로 나타내면 다음과 같습니다.</p>
</li>
<li><p><img src="https://www.simonho.ca/wp-content/uploads/2018/02/XOR_gate.png" alt="XOR gate"></p>
</li>
<li><p>위와 같은 그래프에서 0과 1(off와 on)을 하나의 선으로 구분할 수 없었습니다. 즉, 하나의 perceptron으로는 AND/OR gate 문제는 해결할 수 있었지만 XOR gate 문제를 해결할 수 없었습니다.</p>
</li>
<li><p>이렇게 하나의 perceptron으로 해결할 수 없는 문제를 해결하기 위해 등장한것이 Multi Layer Perceptron입니다.</p>
</li>
<li><p>다시 한번 위의 그래프를 봤을때, 하나의 선이 아니라 두개의 선으로는 0과 1(off와 on)을 구분할 수 있을까요?</p>
</li>
<li><p>답은 YES입니다. 즉, 두개 이상의 perceptron으로는 XOR gate문제를 해결할 수 있었습니다.</p>
</li>
<li><p>4개의 Layer를 갖는 모델을 구현해 확인해 보겠습니다.</p>
</li>
<li><p>먼저 XOR gate에 해당하는 데이터를 만들고,</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># XOR 데이터</span></span><br><span class="line">X = torch.FloatTensor([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">1</span>]]).to(device)</span><br><span class="line">Y = torch.FloatTensor([[<span class="number">0</span>], [<span class="number">1</span>], [<span class="number">1</span>], [<span class="number">0</span>]]).to(device)</span><br></pre></td></tr></table></figure>

<ul>
<li>4개의 layer를 생성해 모델을 정의해줍니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 4개의 레이어가 있는 MLP(Multi Layer Perceptron)</span></span><br><span class="line">linear1 = torch.nn.Linear(<span class="number">2</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear2 = torch.nn.Linear(<span class="number">10</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear3 = torch.nn.Linear(<span class="number">10</span>, <span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">linear4 = torch.nn.Linear(<span class="number">10</span>, <span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 정의</span></span><br><span class="line">model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid,</span><br><span class="line">                            linear4, sigmoid).to(device)</span><br></pre></td></tr></table></figure>

<ul>
<li>이후 loss와 optimizer를 정의해주고,</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  loss / optimizer 정의</span></span><br><span class="line">criterion = torch.nn.BCELoss().to(device)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>모델을 통해 weight와 bias를 학습합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 학습</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10001</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    hypothesis = model(X)</span><br><span class="line"></span><br><span class="line">    loss = criterion(hypothesis, Y)</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        print(epoch, loss.item())</span><br><span class="line"><span class="comment">#&gt;&gt;&gt; print</span></span><br><span class="line"><span class="number">0</span> <span class="number">0.6948983669281006</span></span><br><span class="line"><span class="number">100</span> <span class="number">0.6931558847427368</span></span><br><span class="line"><span class="number">200</span> <span class="number">0.6931535005569458</span></span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line"><span class="number">9800</span> <span class="number">0.00016415018762927502</span></span><br><span class="line"><span class="number">9900</span> <span class="number">0.00016021561168599874</span></span><br><span class="line"><span class="number">10000</span> <span class="number">0.0001565046259202063</span></span><br></pre></td></tr></table></figure>

<ul>
<li>학습이 끝나면 실제값과 예측값이 잘 맞아 떨어지는지 확인합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 학습 후 실제값과 예측값 비교해보기</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    hypothesis = model(X)</span><br><span class="line">    predict = (hypothesis &gt; <span class="number">0.5</span>).float()</span><br><span class="line">    accuracy = (predict == Y).float().mean()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Hyptthesis : '</span>, hypothesis.detach().cpu().numpy(),</span><br><span class="line">          <span class="string">'\nCorrect : '</span>,predict.detach().cpu().numpy(),</span><br><span class="line">          <span class="string">'\nAccuracy : '</span>,accuracy.item())</span><br><span class="line"><span class="comment">#&gt;&gt;&gt; print</span></span><br><span class="line">Hyptthesis :  [[<span class="number">1.1168354e-04</span>]</span><br><span class="line"> [<span class="number">9.9982882e-01</span>]</span><br><span class="line"> [<span class="number">9.9984241e-01</span>]</span><br><span class="line"> [<span class="number">1.8533420e-04</span>]] </span><br><span class="line">Correct :  [[<span class="number">0.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span>]] </span><br><span class="line">Accuracy :  <span class="number">1.0</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>위의 결과를 통해 Multi Layer Perceptron을 사용하면 XOR gate문제를 해결할 수 있음을 확인했습니다.</p>
</li>
<li><p><a href="https://www.simonho.ca/machine-learning/xor-logic-gate-neural-networks/">참고</a></p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/perceptron_XOR_problem.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-08T19:59:00.000Z">2020-04-08</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    3 minutes read (About 439 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/08/Pytorch-Logistic-regression/">Pytorch_Logistic_regression</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Logistic-regression-Binary-Classifier만들기"><a href="#Pytorch-Logistic-regression-Binary-Classifier만들기" class="headerlink" title="Pytorch Logistic regression(Binary Classifier만들기)"></a>Pytorch Logistic regression(Binary Classifier만들기)</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>0과 1 두 가지를 분류하기 위한 binary classifier를 만들어 보았습니다.</p>
</li>
<li><p>binary 분류 문제를 해결하기 위해서는 선형 회구와 같은 실수값이 아닌 확률값을 예측해야 합니다.</p>
</li>
<li><p>이를 위해 선형 함수와 sigmoid 함수를 통과하는 BinaryClassifier를 다음과 같이 만듭니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모델 정의</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinaryClassifier</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="number">8</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.sigmoid(self.linear(x))</span><br><span class="line">		</span><br><span class="line">model = BinaryClassifier()</span><br></pre></td></tr></table></figure>

<ul>
<li>학습에 사용할 모델을 만들었으니 사용할 데이터를 불러오고 optimizer를 정의합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">xy = np.loadtxt(<span class="string">'data/data-03-diabetes.csv'</span>, delimiter=<span class="string">','</span>, dtype=np.float32)</span><br><span class="line">x_data = xy[:, <span class="number">0</span>:<span class="number">-1</span>]</span><br><span class="line">y_data = xy[:, [<span class="number">-1</span>]]</span><br><span class="line">x_train = torch.FloatTensor(x_data)</span><br><span class="line">y_train = torch.FloatTensor(y_data)</span><br><span class="line"></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>마지막으로 epoch수 만큼 반복해 학습합니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs + <span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">    hypothesis = model(x_train)</span><br><span class="line"></span><br><span class="line">    loss = F.binary_cross_entropy(hypothesis, y_train)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">        prediction = (hypothesis &gt;= torch.FloatTensor([<span class="number">0.5</span>])).float()</span><br><span class="line">        correct_prediction = (prediction == y_train).float()</span><br><span class="line">        accuracy = correct_prediction.sum().item() / len(correct_prediction)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">'Epoch : &#123;:4d&#125;/&#123;&#125; loss : &#123;:6f&#125; Accuracy : &#123;:2.2f&#125;'</span>.format(</span><br><span class="line">            epoch, epochs, loss.item(), accuracy*<span class="number">100</span></span><br><span class="line">        ))</span><br></pre></td></tr></table></figure>

<ul>
<li><p>Accuracy를 나타내줄때 올바른 예측은 hypothesis(predict) 값이 0.5보다 큰값을 기준으로 사용했습니다. </p>
</li>
<li><p>binary 문제를 해결하기 위해서는 sigmoid함수를 사용했습니다. 다음 강의때 다시한번 적겠지만 세개 이상의 class를 가지는 분류문제를 해결하기 위해서는 softmax함수를 사용해야 한다는 차이점을 기억해야겠습니다.</p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Logistic_Regression_with_nnModule.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-07T17:42:35.000Z">2020-04-07</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 638 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/07/Pytorch-data-loading-with-DataLoader/">Pytorch_data_loading_with_DataLoader</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-DataLoader를-통한-data-loading"><a href="#Pytorch-DataLoader를-통한-data-loading" class="headerlink" title="Pytorch DataLoader를 통한 data loading"></a>Pytorch DataLoader를 통한 data loading</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>DataLoader를 통해 데이터를 batch_size 만큼 나누어 읽어오기 위해서는 torch.utils.data 의 Dataset을 상속받는 클래스를 정의해야 합니다.</p>
</li>
<li><p>자기만의 Dataset을 만든 뒤, <code>__len__</code> 과 <code>__getitem__</code> 메서드를 overriding해서 사용해야 합니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">	...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">	...</span><br></pre></td></tr></table></figure>

<ul>
<li><p>Dataset의 소스는 <a href="https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#Dataset">이곳</a>에서 확인할 수 있으며, DataLoader에 대한 한글 설명은 <a href="https://deepbaksuvision.github.io/Modu_ObjectDetection/posts/03_01_dataloader.html">이곳</a>을 참고할 수 있습니다.</p>
</li>
<li><p>간단한 Linear regression 모델과 데이터를 만들어서 실습해 보았습니다.</p>
</li>
<li><p>먼저 Dataset을 상속받는 저만의 Dataset과 <code>__len__</code> 과 <code>__getitem__</code> 메서드를 만들어 보겠습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.x_train = [[<span class="number">73</span>, <span class="number">80</span>, <span class="number">75</span>],</span><br><span class="line">                         [<span class="number">93</span>, <span class="number">88</span>, <span class="number">83</span>],</span><br><span class="line">                         [<span class="number">89</span>, <span class="number">91</span>, <span class="number">90</span>],</span><br><span class="line">                         [<span class="number">96</span>,<span class="number">98</span>, <span class="number">100</span>],</span><br><span class="line">                         [<span class="number">73</span>, <span class="number">66</span>, <span class="number">70</span>]]</span><br><span class="line">        self.y_train = [[<span class="number">152</span>], [<span class="number">185</span>], [<span class="number">180</span>], [<span class="number">196</span>], [<span class="number">142</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.x_train)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        x = torch.FloatTensor(self.x_train[idx])</span><br><span class="line">        y = torch.FloatTensor(self.y_train[idx])</span><br><span class="line">        <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure>

<ul>
<li>이렇게 만들어진 MyDataset은 <code>torch.utils.data</code>의 <code>DataLoader</code>를 통해 batch_size를 조절할 수 있습니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataset = MyDataset()</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">2</span>, shuffle=<span class="literal">True</span>) <span class="comment"># shuffle 은 데이터를 섞어서 각각의 배치를 만들어준다는 뜻이다.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>DataLoader를 통해 만들어진 객체는 iterable한 객체이기 때문에 다음과 같이 출력해서 확인해 볼 수도 있습니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">a = iter(dataloader)</span><br><span class="line">print(next(a))</span><br><span class="line">print(next(a))</span><br><span class="line">print(next(a))</span><br><span class="line"><span class="comment">#&gt;&gt;&gt;</span></span><br><span class="line">[tensor([[ <span class="number">73.</span>,  <span class="number">80.</span>,  <span class="number">75.</span>],</span><br><span class="line">        [ <span class="number">96.</span>,  <span class="number">98.</span>, <span class="number">100.</span>]]), tensor([[<span class="number">152.</span>],</span><br><span class="line">        [<span class="number">196.</span>]])]</span><br><span class="line">[tensor([[<span class="number">73.</span>, <span class="number">66.</span>, <span class="number">70.</span>],</span><br><span class="line">        [<span class="number">93.</span>, <span class="number">88.</span>, <span class="number">83.</span>]]), tensor([[<span class="number">142.</span>],</span><br><span class="line">        [<span class="number">185.</span>]])]</span><br><span class="line">[tensor([[<span class="number">89.</span>, <span class="number">91.</span>, <span class="number">90.</span>]]), tensor([[<span class="number">180.</span>]])]</span><br></pre></td></tr></table></figure>

<ul>
<li><p>저만의 MyDataset에 입력한 데이터가 DataLoader를 통해 지정한 배치로 나눠져서 정상적으로 출력되는것을 확인할 수 있습니다.</p>
</li>
<li><p>이제 Linear regression 모델, optimizer를 다음과 같이 만든 뒤,</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultivariateLinearRegressionModel</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.linear = nn.Linear(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.linear(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MultivariateLinearRegressionModel()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>DataLoader를 통해 데이터를 불러와 학습해 보겠습니다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> batch_idx, train <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line">        xt, yt = train</span><br><span class="line"></span><br><span class="line">        prediction = model(xt)</span><br><span class="line"></span><br><span class="line">        loss = F.mse_loss(prediction, yt)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        print(<span class="string">'Epoch &#123;:4d&#125;/&#123;&#125; Batch : &#123;&#125;/&#123;&#125; Cost : &#123;:.6f&#125;'</span>.format(</span><br><span class="line">            epoch, epochs, batch_idx+<span class="number">1</span>, len(dataloader), loss.item()</span><br><span class="line">        ))</span><br></pre></td></tr></table></figure>

<ul>
<li>epochs 수만큼 학습을 하는 for문 안에 또 하나의 for문이 들어가 있는것을 확인할 수 있습니다. 안쪽 for문에서 batch_size만큼 나눠진 train 데이터를 model을 통해 학습하는 과정을 구현해 볼 수 있었습니다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Loading_data.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-06T15:21:16.000Z">2020-04-06</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    2 minutes read (About 334 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/06/Pytorch-Multivariable-Linear-regression/">Pytorch_Multivariable_Linear_regression</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Multivariable-Linear-regression-기본-정리"><a href="#Pytorch-Multivariable-Linear-regression-기본-정리" class="headerlink" title="Pytorch Multivariable Linear regression 기본 정리"></a>Pytorch Multivariable Linear regression 기본 정리</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>두 개 이상의 x값으로부터 y값을 예측하는 간단한 모델을 만들어보자.</p>
</li>
<li><p>간단한 예제를 위해 (5,3) 의 train_x data를, (5,1) 의 train_y 데이터를 만든다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[<span class="number">73</span>, <span class="number">80</span>, <span class="number">75</span>],</span><br><span class="line">                             [<span class="number">93</span>, <span class="number">88</span>, <span class="number">83</span>],</span><br><span class="line">                             [<span class="number">89</span>, <span class="number">91</span>, <span class="number">90</span>],</span><br><span class="line">                             [<span class="number">96</span>,<span class="number">98</span>, <span class="number">100</span>],</span><br><span class="line">                             [<span class="number">73</span>, <span class="number">66</span>, <span class="number">70</span>]])</span><br><span class="line">y_train = torch.FloatTensor([[<span class="number">152</span>], [<span class="number">185</span>], [<span class="number">180</span>], [<span class="number">196</span>], [<span class="number">142</span>]])</span><br></pre></td></tr></table></figure>

<ul>
<li>선형 회귀 모델을 만들것이므로 우리가 학습해야하는 변수는 w 와 b 두 가지이다. 이를 torch.zeros 를 이용해 만들고 requires_grad=True 로 설정해 학습할 데이터로 설정하자.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w = torch.zeros((<span class="number">3</span>,<span class="number">1</span>), requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>모델을 통해 구한 hypothesis와 실제값의 차이로부터 loss를 구하기 위해 MSE를 사용하고, SGD optimizer를 통해 w 와 b를 개선한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD([w,b], lr=<span class="number">1e-5</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>epochs 수만큼 모델을 학습시킨다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs+<span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">    hypothesis = x_train.matmul(w) + b <span class="comment"># 모델을 통해 구해지는 predict값</span></span><br><span class="line"></span><br><span class="line">    loss = torch.mean((hypothesis - y_train) ** <span class="number">2</span>) <span class="comment"># predict와 train 데이터로부터 구하는 loss</span></span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad <span class="comment"># gradient 초기화</span></span><br><span class="line">    loss.backward()		<span class="comment"># gradient 계산</span></span><br><span class="line">    optimizer.step()	<span class="comment"># w 와 b 개선</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Epoch &#123;:4d&#125;/&#123;&#125; hypothesis : &#123;&#125; Cost : &#123;:.6f&#125;'</span>. format(</span><br><span class="line">        epoch, epochs, hypothesis.squeeze().detach(), loss.item()</span><br><span class="line">    ))</span><br></pre></td></tr></table></figure>

<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Multivariable_Linear_regression.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-04-02T23:26:54.000Z">2020-04-02</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 534 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/04/02/Pytorch-Linear-regression-%EA%B8%B0%EB%B3%B8%EC%A0%95%EB%A6%AC/">Pytorch_Linear_regression_기본정리</a>
            
        </h1>
        <div class="content">
            <h1 id="Pytorch-Linear-regression-기본-정리"><a href="#Pytorch-Linear-regression-기본-정리" class="headerlink" title="Pytorch Linear regression 기본 정리"></a>Pytorch Linear regression 기본 정리</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>하나의 x값을 통해 하나의 y를 예측하는 간단한 모델을 만들어보자.</p>
</li>
<li><p>다음과 같이 세개의 데이터를 만들고 이를 통해 간단한 선형 예측 모델을 학습시켜본다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train = torch.FloatTensor([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]])</span><br><span class="line">y_train = torch.FloatTensor([[<span class="number">2</span>], [<span class="number">4</span>], [<span class="number">6</span>]])</span><br></pre></td></tr></table></figure>

<ul>
<li>선형 모델에서 x값이 주어졌을 때 y값(hypothesis-H(x))을 계산하기 위해서는 다음과 같은 식을 따르게 된다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">H(x) = W * x + b</span><br></pre></td></tr></table></figure>

<ul>
<li><p>가지고 있는 데이터를 위 식을 통해 학습시키고자 한다면 우리가 알아야 하는 값 즉, 학습해야 하는 값은 W 와 b이다.</p>
</li>
<li><p>“requires_grad=True” 를 설정하여 다음과 같이 0으로 초기화된 W 와 b 를 만들 수 있다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">w = torch.zeros(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.zeros(<span class="number">1</span>, requires_grad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>우리가 만든 모델을 평가하기 위해서는 Mean Squared Error(MSE) 를 사용할 것입니다.</p>
</li>
<li><p>MSE는 예측값과 실제값의 차이를 제곱한 후 평균을 구한 값으로 다음과 같이 나타낼 수 있습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = torch.mean((hypothesis - y_train) ** <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>loss 를 구했다면 이를 통해 학습해야 하는 W 와 b 값을 개선해야 합니다.</p>
</li>
<li><p>이를 위해 Stochastic gradient descent(SGD)를 사용할 것입니다.</p>
</li>
<li><p>optim 라이브러리의 SGD에 학습할 tensor를 리스트 형태로 넣어주고 learing rate를 지정해 다음과 같이 나타낼 수 있습니다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = torch.optim.SGD([w, b], lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>optimizer를 정의했다면 아래와 같은 순서를 통해 W와 b를 개선해준다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">optimizer.zero_grad()  <span class="comment"># gradient 초기화</span></span><br><span class="line">loss.backward()		   <span class="comment"># gradient 계산</span></span><br><span class="line">optimizer.step()	   <span class="comment"># W 와 b 개선</span></span><br></pre></td></tr></table></figure>

<ul>
<li>이러한 학습 방법을 따라 모델을 100회 한 후 x가 4일때의 y값을 살펴보면 8에 근접하는 값이 나오는 것을 확인할 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x_test = torch.FloatTensor([[<span class="number">4</span>]])</span><br><span class="line">print(x_test * w + b)</span><br><span class="line"><span class="comment">#&gt;&gt;&gt; tensor([[7.5598]], grad_fn=&lt;AddBackward0&gt;)</span></span><br></pre></td></tr></table></figure>

<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Linear_regression.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-03-29T20:31:22.000Z">2020-03-29</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/About-Python/">About Python</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 566 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/03/29/%ED%8C%8C%EC%9D%B4%EC%8D%AC-dataframe-loc-iloc-%EC%9D%B8%EB%8D%B1%EC%8B%B1/">파이썬_dataframe_loc_iloc_인덱싱</a>
            
        </h1>
        <div class="content">
            <h1 id="파이썬-dataframe-인덱싱하기"><a href="#파이썬-dataframe-인덱싱하기" class="headerlink" title="파이썬 dataframe 인덱싱하기"></a>파이썬 dataframe 인덱싱하기</h1><ul>
<li><p>dataframe을 인덱싱할때 loc과 iloc을 사용할 수 있다.</p>
</li>
<li><p>다음과 같은 데이터 프레임을 예시로 두 가지를 살펴보자.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;</span><br><span class="line">    <span class="string">'age'</span> :     [<span class="number">13</span>,<span class="number">17</span>,<span class="number">19</span>,<span class="number">21</span>,<span class="number">23</span>],</span><br><span class="line">    <span class="string">'class'</span> : [<span class="string">'math'</span>,<span class="string">'science'</span>,<span class="string">'english'</span>,<span class="string">'math'</span>,<span class="string">'science'</span>],</span><br><span class="line">    <span class="string">'city'</span> :    [<span class="string">'A'</span>,<span class="string">'B'</span>,<span class="string">'A'</span>,<span class="string">'C'</span>,<span class="string">'B'</span>],</span><br><span class="line">    <span class="string">'gender'</span> :  [ <span class="string">'M'</span>, <span class="string">'F'</span>, <span class="string">'F'</span>, <span class="string">'M'</span>, <span class="string">'M'</span>],</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">print(df)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">   age    <span class="class"><span class="keyword">class</span> <span class="title">city</span> <span class="title">gender</span></span></span><br><span class="line"><span class="class">0   13     <span class="title">math</span>    <span class="title">A</span>      <span class="title">M</span></span></span><br><span class="line"><span class="class">1   17  <span class="title">science</span>    <span class="title">B</span>      <span class="title">F</span></span></span><br><span class="line"><span class="class">2   19  <span class="title">english</span>    <span class="title">A</span>      <span class="title">F</span></span></span><br><span class="line"><span class="class">3   21     <span class="title">math</span>    <span class="title">C</span>      <span class="title">M</span></span></span><br><span class="line"><span class="class">4   23  <span class="title">science</span>    <span class="title">B</span>      <span class="title">M</span></span></span><br></pre></td></tr></table></figure>




<ul>
<li><p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html">loc</a>을 사용하여 인덱싱하기</p>
<ul>
<li><p>loc 인덱싱은 두 가지 사용법이 있다.</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df.loc[행 인덱스값]</span><br><span class="line"></span><br><span class="line"><span class="keyword">or</span></span><br><span class="line"></span><br><span class="line">df.loc[행 인덱스값, 열 인덱스값]</span><br></pre></td></tr></table></figure>
</li>
<li><p>이를 이용해 둘째, 셋째 행만을 가져오면 다음과 같다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ex1 = print(df.loc[<span class="number">1</span>:<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">print(ex1)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">   age    <span class="class"><span class="keyword">class</span> <span class="title">city</span> <span class="title">gender</span></span></span><br><span class="line"><span class="class">1   17  <span class="title">science</span>    <span class="title">B</span>      <span class="title">F</span></span></span><br><span class="line"><span class="class">2   19  <span class="title">english</span>    <span class="title">A</span>      <span class="title">F</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>boolean 시리즈를 행을 선택하는 인덱스값으로 사용할 수 있다.</p>
</li>
<li><p>이를 이용하여 A 도시에 사는 행을 선택하면 다음과 같다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ex2 = df.loc[df.city == <span class="string">'A'</span>]</span><br><span class="line"></span><br><span class="line">print(ex2)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">   age    <span class="class"><span class="keyword">class</span> <span class="title">city</span> <span class="title">gender</span></span></span><br><span class="line"><span class="class">0   13     <span class="title">math</span>    <span class="title">A</span>      <span class="title">M</span></span></span><br><span class="line"><span class="class">2   19  <span class="title">english</span>    <span class="title">A</span>      <span class="title">F</span></span></span><br></pre></td></tr></table></figure>
</li>
<li><p>한 걸음 더 나가서 A 도시에 사는 사람들의 성별을 나타내는 시리즈를 알고 싶다.</p>
</li>
<li><p>이럴때는 열 인덱스값을 추가해서 다음과 같이 얻어낼 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ex3 = df.loc[df.city == <span class="string">'A'</span>, <span class="string">'gender'</span>]</span><br><span class="line"></span><br><span class="line">print(ex3)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"><span class="number">0</span>    M</span><br><span class="line"><span class="number">2</span>    F</span><br></pre></td></tr></table></figure>
</li>
<li><p>이렇게 열 인덱스값을 추가하여 다음과 같이 나이와 성별만을 갖는 두개의 행으로 datframe을 슬라이싱 할 수도 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ex4 = df.loc[<span class="number">1</span>:<span class="number">2</span>,[<span class="string">'age'</span>,<span class="string">'gender'</span>]]</span><br><span class="line"></span><br><span class="line">print(ex4)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">   age gender</span><br><span class="line"><span class="number">1</span>   <span class="number">17</span>      F</span><br><span class="line"><span class="number">2</span>   <span class="number">19</span>      F</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p><a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html">iloc</a>을 사용하여 인덱싱하기</p>
<ul>
<li><p>iloc은 integer-location based indexing 로서 정수(integer)를 인덱스값으로 받는다는 점이 loc과의 차이점이다.</p>
</li>
<li><p>loc의 마지막 예제를 iloc을 통해 나타내면 다음과 같다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ex5 = df.iloc[<span class="number">1</span>:<span class="number">3</span>,[<span class="number">0</span>,<span class="number">3</span>]]</span><br><span class="line"></span><br><span class="line">print(ex5)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">   age gender</span><br><span class="line"><span class="number">1</span>   <span class="number">17</span>      F</span><br><span class="line"><span class="number">2</span>   <span class="number">19</span>      F</span><br></pre></td></tr></table></figure>
</li>
<li><p>ex4와 ex5의 코드를 살펴보면 단순히 정수값을 받는다는 점 이외에도 차이점이 있다.</p>
</li>
<li><p>loc 은 행 인덱스값을 1:2 까지로 나타내면 마지막 행까지 모두 포함한 결과를 내놓지만, iloc은 행 인덱스값의 마지막 행을 포함하지 않기 때문에 1:3 으로 나타내줬다.</p>
</li>
</ul>
</li>
</ul>

        </div>
        
        
        
    </div>
</div>









    
<div class="card card-transparent">
    <nav class="pagination is-centered" role="navigation" aria-label="pagination">
        <div class="pagination-previous">
            <a class="is-flex-grow has-text-black-ter" href="/tags/Python/">Previous</a>
        </div>
        <div class="pagination-next">
            <a class="is-flex-grow has-text-black-ter" href="/tags/Python/page/3/">Next</a>
        </div>
        <ul class="pagination-list is-hidden-mobile">
            
            <li><a class="pagination-link has-text-black-ter" href="/tags/Python/">1</a></li>
            
            <li><a class="pagination-link is-current" href="/tags/Python/page/2/">2</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/tags/Python/page/3/">3</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/tags/Python/page/4/">4</a></li>
            
        </ul>
    </nav>
</div>
</div>
                




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="" src="/images/avatar.png" alt="Already-Ready">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        Already-Ready
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        I&#39;m Going Now
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Seongnam city</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Posts
                    </p>
                    <a href="/archives">
                        <p class="title has-text-weight-normal">
                            47
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Categories
                    </p>
                    <a href="/categories">
                        <p class="title has-text-weight-normal">
                            12
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Tags
                    </p>
                    <a href="/tags">
                        <p class="title has-text-weight-normal">
                            8
                        </p>
                    </a>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">
                Follow</a>
        </div>
        
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Github" href="https://github.com/Already-Ready">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Facebook" href="https://facebook.com">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Twitter" href="https://twitter.com">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Dribbble" href="https://dribbble.com">
                
                <i class="fab fa-dribbble"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Links
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://github.com/Already-Ready" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">My_Github</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">github.com</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/CS-basic/">
            <span class="level-start">
                <span class="level-item">CS basic</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">6</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/CS-basic/CtCI/">
            <span class="level-start">
                <span class="level-item">CtCI</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Go/">
            <span class="level-start">
                <span class="level-item">Go</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Go/About-Go/">
            <span class="level-start">
                <span class="level-item">About Go</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Go/tutorial/">
            <span class="level-start">
                <span class="level-item">tutorial</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Python/">
            <span class="level-start">
                <span class="level-item">Python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">22</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Python/About-Python/">
            <span class="level-start">
                <span class="level-item">About Python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Python/Pytorch/">
            <span class="level-start">
                <span class="level-item">Pytorch</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">18</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/baekjoon/">
            <span class="level-start">
                <span class="level-item">baekjoon</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">11</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/baekjoon/Go/">
            <span class="level-start">
                <span class="level-item">Go</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/baekjoon/python/">
            <span class="level-start">
                <span class="level-item">python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">11</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/github-io/">
            <span class="level-start">
                <span class="level-item">github.io</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/CS/" style="font-size: 14px;">CS</a> <a href="/tags/CtCI/" style="font-size: 12px;">CtCI</a> <a href="/tags/Go/" style="font-size: 16px;">Go</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/Pytorch/" style="font-size: 18px;">Pytorch</a> <a href="/tags/baekjoon/" style="font-size: 16px;">baekjoon</a> <a href="/tags/github-io/" style="font-size: 10px;">github.io</a> <a href="/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/" style="font-size: 10px;">블로그</a>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
            <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2020/06/08/Pytorch-About-RESNET/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_About_RESNET">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-06-08T21:15:31.000Z">2020-06-08</time></div>
                    <a href="/2020/06/08/Pytorch-About-RESNET/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_About_RESNET</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/24/Pytorch-About-SGD/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_About_SGD">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-24T14:33:43.000Z">2020-05-24</time></div>
                    <a href="/2020/05/24/Pytorch-About-SGD/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_About_SGD</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/14/Pytorch-VGG-with-CIFAR10/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_VGG_with_CIFAR10">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-14T18:42:19.000Z">2020-05-14</time></div>
                    <a href="/2020/05/14/Pytorch-VGG-with-CIFAR10/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_VGG_with_CIFAR10</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/12/Pytorch-About-VGG-Advance-CNN/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_About_VGG_Advance_CNN">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-12T11:57:01.000Z">2020-05-12</time></div>
                    <a href="/2020/05/12/Pytorch-About-VGG-Advance-CNN/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_About_VGG_Advance_CNN</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/07/Pytorch-ImageFolder/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_ImageFolder">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-07T20:40:48.000Z">2020-05-07</time></div>
                    <a href="/2020/05/07/Pytorch-ImageFolder/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_ImageFolder</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2020/06/">
                <span class="level-start">
                    <span class="level-item">June 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/05/">
                <span class="level-start">
                    <span class="level-item">May 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">6</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">April 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">12</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">March 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/02/">
                <span class="level-start">
                    <span class="level-item">February 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/01/">
                <span class="level-start">
                    <span class="level-item">January 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">17</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/12/">
                <span class="level-start">
                    <span class="level-item">December 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CS/">
                        <span class="tag">CS</span>
                        <span class="tag is-grey">6</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CtCI/">
                        <span class="tag">CtCI</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Go/">
                        <span class="tag">Go</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Python/">
                        <span class="tag">Python</span>
                        <span class="tag is-grey">31</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Pytorch/">
                        <span class="tag">Pytorch</span>
                        <span class="tag is-grey">18</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/baekjoon/">
                        <span class="tag">baekjoon</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/github-io/">
                        <span class="tag">github.io</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/">
                        <span class="tag">블로그</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
        
        </div>
    
</div>

                




<div class="column is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only has-order-3 column-right ">
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2020/06/08/Pytorch-About-RESNET/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_About_RESNET">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-06-08T21:15:31.000Z">2020-06-08</time></div>
                    <a href="/2020/06/08/Pytorch-About-RESNET/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_About_RESNET</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/24/Pytorch-About-SGD/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_About_SGD">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-24T14:33:43.000Z">2020-05-24</time></div>
                    <a href="/2020/05/24/Pytorch-About-SGD/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_About_SGD</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/14/Pytorch-VGG-with-CIFAR10/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_VGG_with_CIFAR10">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-14T18:42:19.000Z">2020-05-14</time></div>
                    <a href="/2020/05/14/Pytorch-VGG-with-CIFAR10/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_VGG_with_CIFAR10</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/12/Pytorch-About-VGG-Advance-CNN/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_About_VGG_Advance_CNN">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-12T11:57:01.000Z">2020-05-12</time></div>
                    <a href="/2020/05/12/Pytorch-About-VGG-Advance-CNN/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_About_VGG_Advance_CNN</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/05/07/Pytorch-ImageFolder/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_ImageFolder">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-05-07T20:40:48.000Z">2020-05-07</time></div>
                    <a href="/2020/05/07/Pytorch-ImageFolder/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_ImageFolder</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2020/06/">
                <span class="level-start">
                    <span class="level-item">June 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/05/">
                <span class="level-start">
                    <span class="level-item">May 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">6</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">April 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">12</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">March 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/02/">
                <span class="level-start">
                    <span class="level-item">February 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/01/">
                <span class="level-start">
                    <span class="level-item">January 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">17</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/12/">
                <span class="level-start">
                    <span class="level-item">December 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CS/">
                        <span class="tag">CS</span>
                        <span class="tag is-grey">6</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CtCI/">
                        <span class="tag">CtCI</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Go/">
                        <span class="tag">Go</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Python/">
                        <span class="tag">Python</span>
                        <span class="tag is-grey">31</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Pytorch/">
                        <span class="tag">Pytorch</span>
                        <span class="tag is-grey">18</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/baekjoon/">
                        <span class="tag">baekjoon</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/github-io/">
                        <span class="tag">github.io</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/">
                        <span class="tag">블로그</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="Hexo" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2020 John Doe&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'http://yoursite.com',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>














<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>