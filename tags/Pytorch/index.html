<!DOCTYPE html>
<html  lang="en">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>Tag: Pytorch - Hexo</title>


    <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/tags/Pytorch/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/images/og_image.png">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/images/og_image.png">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    
    
    
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    
    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="Hexo" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="/tags">Tags</a>
                
                <a class="navbar-item"
                href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-6-widescreen has-order-2 column-main"><div class="card">
    <div class="card-content">
        <nav class="breadcrumb" aria-label="breadcrumbs">
        <ul>
            <li><a href="/tags">Tags</a></li>
            <li class="is-active"><a href="#" aria-current="page">Pytorch</a></li>
        </ul>
        </nav>
    </div>
</div>

    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-07-05T15:00:04.000Z">2020-07-05</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    5 minutes read (About 822 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/07/05/Pytorch-RNN-long-sequence/">Pytorch_RNN_long_sequence</a>
            
        </h1>
        <div class="content">
            <h1 id="RNN-Long-Sequence-다루기"><a href="#RNN-Long-Sequence-다루기" class="headerlink" title="RNN Long Sequence 다루기"></a>RNN Long Sequence 다루기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p><a href="https://already-ready.github.io/2020/07/02/Pytorch-RNN-intro/">RNN intro</a>를 통해 hello 예제를 살펴보았다.</p>
</li>
<li><p>비슷하게 one hot encoding을 통해 hello보다 긴 문장을 다루어보고자 한다.</p>
</li>
<li><p>먼저, 문장으로부터 각 알파벳과 인덱스를 매칭시키는 dict를 만들고 이를 활용하고자 한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sentence = (<span class="string">"if you want to build a ship, don't drum up people together to "</span></span><br><span class="line">            <span class="string">"collect wood and don't assign them tasks and work, but rather "</span></span><br><span class="line">            <span class="string">"teach them to long for the endless immensity of the sea."</span>)</span><br><span class="line"></span><br><span class="line">char_set = list(set(sentence))</span><br><span class="line">char_dic = &#123;c:i <span class="keyword">for</span> i, c <span class="keyword">in</span> enumerate(char_set)&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>윈도우 크기를 정하고 그에 맞게 문장을 잘라서 input data X로 사용하고 하나의 character만큼 오른쪽으로 쉬프트한 윈도우 크기의 문장을 Y로 사용하고자 한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">예를 들어, 윈도우 크기가 <span class="number">5</span>라면 처음 X는</span><br><span class="line">X = if yo --&gt; Y = f you</span><br><span class="line">가 되는 방식이다.</span><br><span class="line"></span><br><span class="line">이 방법을 통해 문장 전체를 윈도우 크기로 순회해서 데이터X와 Y를 만든다.</span><br><span class="line"></span><br><span class="line">x_data = []</span><br><span class="line">y_data = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(sentence) - sequence_length):</span><br><span class="line">    x = sentence[i: i+sequence_length]</span><br><span class="line">    y = sentence[i+<span class="number">1</span>: i+sequence_length+<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    x_data.append([char_dic[c] <span class="keyword">for</span> c <span class="keyword">in</span> x])</span><br><span class="line">    y_data.append([char_dic[c] <span class="keyword">for</span> c <span class="keyword">in</span> y])</span><br><span class="line"></span><br><span class="line">x_one_hot = [np.eye(dic_size)[x] <span class="keyword">for</span> x <span class="keyword">in</span> x_data]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X = torch.FloatTensor(x_one_hot).to(device)</span><br><span class="line">Y = torch.LongTensor(y_data).to(device)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>이제 원핫인코딩된 X로부터 라벨값 Y를 예측하는 문제의 데이터가 만들어졌다.</p>
</li>
<li><p>RNN모델을 만들때 이전과는 다르게 두 층의 RNN layer와 fully connected layer를 이용해보고자 한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input_dim, hidden_dim, layers)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        self.rnn = torch.nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># num_layers를 설정함으로써 RNN layer를 여러겹 쌓을 수 있다.</span></span><br><span class="line">        self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x, _status = self.rnn(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = Net(dic_size, hiddend_size, <span class="number">2</span>).to(device)</span><br></pre></td></tr></table></figure>

<ul>
<li>위의 모델을 통해 학습하면서 예측을 통해 완성되는 문장을 확인해본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">criterion = torch.nn.CrossEntropyLoss().to(device)</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=learning_rate)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    outputs = net(X)</span><br><span class="line">    loss = criterion(outputs.view(<span class="number">-1</span>,dic_size), Y.view(<span class="number">-1</span>))</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    results = outputs.argmax(dim=<span class="number">2</span>)</span><br><span class="line">    predict_str = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j, result <span class="keyword">in</span> enumerate(results):</span><br><span class="line">        <span class="keyword">if</span> j==<span class="number">0</span>:</span><br><span class="line">            predict_str += <span class="string">''</span>.join([char_set[t] <span class="keyword">for</span> t <span class="keyword">in</span> result])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            predict_str += char_set[result[<span class="number">-1</span>]]</span><br><span class="line"></span><br><span class="line">    print(predict_str)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>마지막에 j가 0일때와 아닐때로 나눈 이유는 첫 번째 예측에서 sequence_length만큼의 문장을 만들어주면 그 이후로부터는 result에서 마지막 문자를 제외하고는 이전 문장과 동일하기 때문이다.</p>
</li>
<li><p>예를 들어 sequence_length가 5이고 j가 0일때 “if yo” 라는 문장을 만들었고 다음 result에서는 “f you”를 예측했다면 이미 이전 문장과 그 다음 문장에서 “f yo” 라는 단어들은 겹치게된다.</p>
</li>
<li><p>따라서, j가 0일때 sequence_length만큼의 문장을 만들고 그 이후로는 result의 마지막 값만을 가져와서 predict_str에 이어붙이게 만들어준다.</p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/RNN_longseq.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-07-02T11:48:28.000Z">2020-07-02</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    5 minutes read (About 725 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/07/02/Pytorch-RNN-intro/">Pytorch_RNN_intro</a>
            
        </h1>
        <div class="content">
            <h1 id="RNN-Intro"><a href="#RNN-Intro" class="headerlink" title="RNN Intro"></a>RNN Intro</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>이미지 데이터가 아니라 순서 정보가 중요한 sequential data를 처리하기 위한 모델</p>
</li>
<li><p><img src="https://adventuresinmachinelearning.com/wp-content/uploads/2017/09/Recurrent-neural-network.png" alt="RNN"></p>
</li>
<li><p>위 그림에서 왼쪽 그림과 같이 RNN 모델을 나타내며 이를 펼치면 오른쪽과 같다.</p>
</li>
<li><p>F 라는 하나의 셀에 입력값 X 가 처리되어 h를 출력하고 다음 셀에 hidden state를 유통한다.</p>
</li>
<li><p>이렇게 하나의 셀에서 hidden state를 다음 셀에 넘겨주고 다음 셀이 입력값 X와 함께 계산해 h를 출력한다면, 해당 출력값 h는 이전 셀의 영향을 이어받을 것이다. 따라서 연속적인 데이터의 정보를 기억하는 효과를 나타낼 수 있게된다.</p>
</li>
<li><p>RNN은 모든 셀이 parameter를 공유한다. 다시 말해, 위의 그림처럼 셀 F 하나를 공유해서 사용하게 된다.</p>
</li>
<li><p>pytorch에서 RNN은 <code>input_size</code>와 <code>hidden_size</code>를 입력받아 정의하고 <code>input_data</code>로 <code>(batch_size, sequential_length, input_size)</code> 형태의 data를 입력한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rnn = torch.nn.RNN(input_size, hidden_size)</span><br><span class="line">outputs, _status = rnn(input_data)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>이때, RNN셀이 batch_size와 sequential_length는 자동으로 파악해준다.</p>
</li>
<li><p>위처럼 RNN을 정의하게 되면 input_data로 <code>(batch_size, sequential_length, input_size)</code>형태를 입력해 <code>(batch_size, sequential_length, hidden_size)</code>형태의 출력값이 나오게 된다.</p>
</li>
<li><p>hello 라는 단어를 통한 예제를 살펴보자.</p>
</li>
<li><p>hello의 각 알파벳을 4차원의 one hot encoding을 해주고 각 알파벳의 조합으로 만들 수 있는 단어 3개를 하나의 배치로 묶어서 사용해본다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">input_size = <span class="number">4</span></span><br><span class="line">hidden_size = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4차원의 one hot 벡터로 표현</span></span><br><span class="line">h = [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">e = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">l = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>]</span><br><span class="line">o = [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># input size는 (3,5,4) 가 된다</span></span><br><span class="line"><span class="comment"># 3 --&gt; batch_size</span></span><br><span class="line"><span class="comment"># 5 --&gt; sequence length : 문자열의 길이 = RNN sequence의 길이</span></span><br><span class="line"><span class="comment"># 4 --&gt; input_size : one hot 벡터의 길이 --&gt; embedding 을 한다면 embedding 크기가 될것</span></span><br><span class="line">input_data_np = np.array([[h,e,l,l,o],</span><br><span class="line">                          [e,o,l,l,l],</span><br><span class="line">                          [l,l,e,e,l]], dtype=np.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># numpy 데이터 텐서로 변환</span></span><br><span class="line">input_data = torch.Tensor(input_data_np)</span><br><span class="line"></span><br><span class="line"><span class="comment"># RNN셀 정의</span></span><br><span class="line">rnn = torch.nn.RNN(input_size, hidden_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># input_data rnn셀 통과</span></span><br><span class="line"><span class="comment"># output size는 2이므로 rnn셀을 통과한 output은 (3,5,2) shape을 가질것이고 이를 확인해본다.</span></span><br><span class="line">output, _status = rnn(input_data)</span><br><span class="line"></span><br><span class="line">print(output)</span><br><span class="line">print(output.shape)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>위와같이 RNN 모델을 정의하고 간단한 데이터를 통해 output을 확인할 수 있었다. hidden_state의 size를 RNN에서 정의하면 이것이 output_data의 크기와 동일하다.</p>
</li>
<li><p>예제를 통해 RNN을 정의할때의 값이 의미하는 바를 파악할 수 있었고 그에 따라 input_data의 shape을 맞춰서 사용하는 방법을 파악할 수 있었다.</p>
</li>
</ul>
<ul>
<li><p>참고</p>
<ul>
<li><a href="https://adventuresinmachinelearning.com/recurrent-neural-networks-lstm-tutorial-tensorflow/">RNN 이미지 참고</a></li>
</ul>
</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-06-25T16:43:18.000Z">2020-06-25</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    7 minutes read (About 983 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/06/25/Pytorch-Activation-plot/">Pytorch_Activation_plot</a>
            
        </h1>
        <div class="content">
            <h1 id="conv-layer의-output을-그려보자"><a href="#conv-layer의-output을-그려보자" class="headerlink" title="conv layer의 output을 그려보자"></a>conv layer의 output을 그려보자</h1><ul>
<li><p>파이토치를 메모리를 아끼기위해 모델에서 나오는 마지막 output만을 저장한다.</p>
</li>
<li><p>그렇다면, 각 conv layer를 통과한 output이 궁금하다면 어떻게 해야할까??</p>
</li>
<li><p>hook을 이용하면 forward와 backward에서 각 레이어의 output을 가져올 수 있다.</p>
</li>
<li><p>여기서는 forward hook을 이용하는 class를 만들어서 이용해보고자 한다.</p>
</li>
<li><p>사용할 모델은 pretrain vgg16모델이며 input으로는 인터넷에서 아무 고양이 사진을 사용해보자.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이미지 불러와서 tensor로 변환 및 사이즈 조정</span></span><br><span class="line">simple_transform = transforms.Compose([transforms.Resize((<span class="number">224</span>,<span class="number">224</span>))</span><br><span class="line">                                       ,transforms.ToTensor()</span><br><span class="line">                                       ,transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">                                      ])</span><br><span class="line">img = Image.open(<span class="string">'../image/cat_1.jpg'</span>)</span><br><span class="line">img = simple_transform(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># unsqueeze_를 통해 shape에 (1,3,224,224) 로 변경 --&gt; batch_size를 추가한것 --&gt; 모델에 넣기위해</span></span><br><span class="line">img.unsqueeze_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pretrained 모델을 불러와서 사용한다. --&gt; 직접 train시킨 모델도 상관없지만 현재 목표는 모델 학습이 아니기 때문에 pretrained모델 사용</span></span><br><span class="line">vgg = models.vgg16(pretrained=<span class="literal">True</span>).cuda()</span><br></pre></td></tr></table></figure>

<ul>
<li>이제 <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module.register_forward_hook">register_forward_hook</a>을 이용해 입력한 layer에 hook을 등록할 수 있게 만든다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerActivations</span><span class="params">()</span>:</span></span><br><span class="line">	<span class="comment"># layer의 output을 저장할 공간을 만들자.</span></span><br><span class="line">    features=<span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">	<span class="comment"># hook을 정의하고 정한 layer_num에 hook을 등록할 수 있게 만든다.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,model,layer_num)</span>:</span></span><br><span class="line">        self.hook = model[layer_num].register_forward_hook(self.hook_fn)</span><br><span class="line">    </span><br><span class="line">	<span class="comment"># 정해진 layer에서 forward함수가 실행되면 output을 저장할 수 있는 함수를 만든다.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">hook_fn</span><span class="params">(self,module,input,output)</span>:</span></span><br><span class="line">        self.features = output.cpu().data.numpy()</span><br><span class="line">		</span><br><span class="line">	<span class="comment"># 등록된 hook을 없애줄 수 있는 함수를 만든다.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remove</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.hook.remove()</span><br></pre></td></tr></table></figure>

<ul>
<li>이제 모델에서 첫번째 conv layer를 통과한 후 나오는 output을 <code>LayerActivations</code>객체에 저장하고 이미지를 그려보자</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vgg.features의 첫번째(0) 에 hook을 등록하고 output을 conv_out에 받도록 한다.</span></span><br><span class="line">conv_out = LayerActivations(vgg.features,<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 가장 처음 가져온 이미지를 vgg모델에 넣어보자.</span></span><br><span class="line"><span class="comment"># 이미지가 모델을 통과할때 위에서 정의한 conv_out에 첫번째 conv layer를 통과하며 내놓은 output을 저장했을 것이다.</span></span><br><span class="line">o = vgg(Variable(img.cuda()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 등록된 hook을 제거해준다.</span></span><br><span class="line">conv_out.remove()</span><br><span class="line"></span><br><span class="line"><span class="comment"># conv_out객체의 features값을 가져오면 우리가 알고싶은 첫번째 conv layer를 통과했을때의 output을 알 수 있다.</span></span><br><span class="line">act = conv_out.features</span><br><span class="line"></span><br><span class="line"><span class="comment"># 30개의 채널만을 plot으로 그려보자.</span></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">50</span>))</span><br><span class="line">fig.subplots_adjust(left=<span class="number">0</span>,right=<span class="number">1</span>,bottom=<span class="number">0</span>,top=<span class="number">0.8</span>,hspace=<span class="number">0</span>,wspace=<span class="number">0.2</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>):</span><br><span class="line">    ax = fig.add_subplot(<span class="number">12</span>,<span class="number">5</span>,i+<span class="number">1</span>,xticks=[],yticks=[])</span><br><span class="line">    ax.imshow(act[<span class="number">0</span>][i])</span><br></pre></td></tr></table></figure>

<ul>
<li><p>첫번째 conv layer를 통과한 output을 그려보면 다음과 같다.</p>
</li>
<li><p><img src="https://github.com/Already-Ready/Already-Ready.github.io/blob/master/images/activation_conv_first.png?raw=true" alt="output conv first"></p>
</li>
<li><p>첫 번째 conv layer는 윤곽선에 집중되는 모습을 확인할 수 있다.</p>
</li>
<li><p>이를 이용해 마지막 conv layer 통과한 결과도 확인해보자.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 마지막 conv layer는 28번째 feature이다.</span></span><br><span class="line"><span class="comment"># 모든 feature를 확인해보고자 한다면 vgg.features 를 입력해서 확인해보자.</span></span><br><span class="line">conv_out = LayerActivations(vgg.features,<span class="number">28</span>)</span><br><span class="line"></span><br><span class="line">o = vgg(Variable(img.cuda()))</span><br><span class="line"></span><br><span class="line">conv_out.remove()</span><br><span class="line"></span><br><span class="line">act = conv_out.features</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">20</span>,<span class="number">50</span>))</span><br><span class="line">fig.subplots_adjust(left=<span class="number">0</span>,right=<span class="number">1</span>,bottom=<span class="number">0</span>,top=<span class="number">0.8</span>,hspace=<span class="number">0</span>,wspace=<span class="number">0.2</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">30</span>):</span><br><span class="line">    ax = fig.add_subplot(<span class="number">12</span>,<span class="number">5</span>,i+<span class="number">1</span>,xticks=[],yticks=[])</span><br><span class="line">    ax.imshow(act[<span class="number">0</span>][i])</span><br></pre></td></tr></table></figure>

<ul>
<li><p><img src="https://github.com/Already-Ready/Already-Ready.github.io/blob/master/images/activation_conv_last.png?raw=true" alt="output conv last"></p>
</li>
<li><p>위는 마지막 conv layer를 통과한 output을 시각화한 것이다.</p>
</li>
<li><p>마지막 레이어는 첫번째 레이어와 다르게 해석하기 어려운 특성을 학습하는 것으로 파악할 수 있었다.</p>
</li>
<li><p>이처럼 필요에 따라서 각 레이어의 output을 hook을 이용해 시각화하는 방법을 공부해 볼 수 있었으며 이를 통해 모델의 각 layer가 집중하는 부분도 확인할 수 있을것이라 생각한다.</p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/deep_with_pytorch/blob/master/Activation_plot_2.ipynb">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-06-22T15:46:49.000Z">2020-06-22</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    3 minutes read (About 462 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/06/22/Pytorch-RESNET-with-CIFAR10/">Pytorch_RESNET_with_CIFAR10</a>
            
        </h1>
        <div class="content">
            <h1 id="CIFAR10에-RESNET모델-적용해보기"><a href="#CIFAR10에-RESNET모델-적용해보기" class="headerlink" title="CIFAR10에 RESNET모델 적용해보기"></a>CIFAR10에 RESNET모델 적용해보기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>RESNET은 3X224X224를 기본 input으로 만들어졌다. 이 모델에 다른 크기를 가진 CIFAR10 이미지를 적용시키고자 한다.</p>
</li>
<li><p>BasicBlock과 Bottleneck class 부분은 그대로 유지하면 RESNET Class만 수정해서 사용하고자 한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># CIFAR10 이미지 --&gt; 32x32 크기의 이미지가 입력이므로 기본 resnet을 일부 수정해서 사용</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block, layers, num_classes=<span class="number">1000</span>, zero_init_residual=False)</span>:</span></span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line">        self.inplanes = <span class="number">16</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>,</span><br><span class="line">                               bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        </span><br><span class="line">        self.layer1 = self._make_layer(block, <span class="number">16</span>, layers[<span class="number">0</span>], stride=<span class="number">1</span>)</span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">32</span>, layers[<span class="number">1</span>], stride=<span class="number">1</span>)</span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">64</span>, layers[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer4 = self._make_layer(block, <span class="number">128</span>, layers[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">128</span> * block.expansion, num_classes)</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.</span><br></pre></td></tr></table></figure>

<ul>
<li><p>위와 같이 layer1~4에서 output의 채널수와 layer2의 strid를 2에서 1로 수정하였고 각 layer를 통과하기전의 max pooling을 삭제하였다.</p>
</li>
<li><p>위와같이 수정했을 때 forward함수에서 각 layer를 통과한 output의 shape을 예상해 볼 수 있다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	<span class="comment"># 3x32x32 이미지를 input으로 넣었을 때, 각 layer를 통과한 후의 output shape</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="comment">#x.shape =[1, 16, 32,32]</span></span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        <span class="comment">#x.shape =[1, 128, 32,32]</span></span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        <span class="comment">#x.shape =[1, 256, 32,32]</span></span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        <span class="comment">#x.shape =[1, 512, 16,16]</span></span><br><span class="line">        x = self.layer4(x)</span><br><span class="line">        <span class="comment">#x.shape =[1, 1024, 8,8]</span></span><br><span class="line">        </span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<ul>
<li>이후 bottleneck을 통한 resnet모델을 정의하고 학습시킬 수 있다. 이렇게 크기가 다른 이미지를 모델에 적용하고자 할 때 resnet class를 수정해서 사용할 수 있었다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Advanced_CNN_RESNET_with_CIFAR10.ipynb">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-06-08T21:15:31.000Z">2020-06-08</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    10 minutes read (About 1501 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/06/08/Pytorch-About-RESNET/">Pytorch_About_RESNET</a>
            
        </h1>
        <div class="content">
            <h1 id="RESNET-모델의-생성과정-살펴보기"><a href="#RESNET-모델의-생성과정-살펴보기" class="headerlink" title="RESNET 모델의 생성과정 살펴보기"></a>RESNET 모델의 생성과정 살펴보기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>CNN advanced model중 하나인 RESNET의 모델 생성과정을 소스코드를 보며 살펴보고자 한다.</p>
</li>
<li><p><a href="https://pytorch.org/docs/stable/_modules/torchvision/models/resnet.html#resnet50">RESNET</a>에서 파이토치 소스코드를 볼 수 있으며 이를 기준으로 모델 생성 과정을 따라가보았다.</p>
</li>
<li><p>RESNET은 RESNET Class외에 BasicBlock과 Bottleneck class를 통해 모델이 생성된다.</p>
</li>
<li><p>RESNET 모델의 생성과정에서 downsample을 이용해 output의 shape을 맞춰주게 된다.</p>
</li>
<li><p>예를 들어, BasicBlock에 stride=2 로 설정해 3x64x64의 이미지가 들어갔을때 아래의 forward함수를 살펴보자.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line">	<span class="comment"># stride값으로 2가 들어갔을 때를 살펴보자</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">2</span>, downsample=None, groups=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 base_width=<span class="number">64</span>, dilation=<span class="number">1</span>, norm_layer=None)</span>:</span></span><br><span class="line">        super(BasicBlock, self).__init__()</span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = norm_layer(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = norm_layer(planes)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">	<span class="comment"># x로 3x64x64의 input이 들어갔을때 각 output의 shape을 생각해보자.</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        identity = x</span><br><span class="line">		<span class="comment"># identity shape = 3x64x64</span></span><br><span class="line">		</span><br><span class="line">        out = self.conv1(x) </span><br><span class="line">		<span class="comment"># out shape = 3x32x32</span></span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">		<span class="comment">#out shape = 3x32x32</span></span><br><span class="line">        out = self.bn2(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line">		</span><br><span class="line">        <span class="comment"># stride를 2로 적용하니 out의 shape과 identity의 shape이 맞지 않아서 </span></span><br><span class="line">		<span class="comment"># 둘을 아래와 같이 더해줄 수 없는 문제가 발생한다.</span></span><br><span class="line">		<span class="comment"># 이러한 문젤르 해결해 shape를 맞춰주도록 사용하는게 downsample 이다.</span></span><br><span class="line">		</span><br><span class="line">		out += identity</span><br><span class="line">		</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<ul>
<li>파이토치에서는 resnet18~152까지 지원하는데 이번에는 resnet50의 생성과정을 살펴보자.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_resnet</span><span class="params">(arch, block, layers, pretrained, progress, **kwargs)</span>:</span></span><br><span class="line">    model = ResNet(block, layers, **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        state_dict = load_state_dict_from_url(model_urls[arch],</span><br><span class="line">                                              progress=progress)</span><br><span class="line">        model.load_state_dict(state_dict)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line">	</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet50</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet50'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br></pre></td></tr></table></figure>

<ul>
<li>resnet50은 Bottleneck class를 ResNet class가 받으며 만들어지며 layers로 [3,4,6,3]의 리스트를 받는다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_forward_impl</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># See note [TorchScript super()]</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<ul>
<li>기본적으로 앞의 conv1, bn1, relu, maxpool를 지난뒤 layer1~4까지를 통과하게 된다. 이때 각 layer는 VGG와 비슷하게 make_layer함수를 통해 이루어지게 되며 다음과 같은 값을 받게 된다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">	<span class="comment"># _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, **kwargs)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block, layers, num_classes=<span class="number">1000</span>, zero_init_residual=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                 groups=<span class="number">1</span>, width_per_group=<span class="number">64</span>, replace_stride_with_dilation=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 norm_layer=None)</span>:</span></span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.	</span><br><span class="line">		<span class="comment"># layers값으로 [3,4,6,3]의 리스트를 받았으므로 아래의 layer1~4는 각각 3,4,6,3을 받게된다.</span></span><br><span class="line">		self.layer1 = self._make_layer(block, <span class="number">64</span>, layers[<span class="number">0</span>]) </span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">128</span>, layers[<span class="number">1</span>], stride=<span class="number">2</span>,</span><br><span class="line">                                       dilate=replace_stride_with_dilation[<span class="number">0</span>])</span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">256</span>, layers[<span class="number">2</span>], stride=<span class="number">2</span>,</span><br><span class="line">                                       dilate=replace_stride_with_dilation[<span class="number">1</span>])</span><br><span class="line">        self.layer4 = self._make_layer(block, <span class="number">512</span>, layers[<span class="number">3</span>], stride=<span class="number">2</span>,</span><br><span class="line">                                       dilate=replace_stride_with_dilation[<span class="number">2</span>])</span><br><span class="line">		<span class="comment"># make_layer함수가 block를 Bottleneck으로, planes로 64 그리고 blocks로 3을 입력받게 된다.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>make_layer에서 layer1이 생성되는 과정은 다음과 같다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_make_layer</span><span class="params">(self, block, planes, blocks, stride=<span class="number">1</span>, dilate=False)</span>:</span></span><br><span class="line">	norm_layer = self._norm_layer</span><br><span class="line">	downsample = <span class="literal">None</span></span><br><span class="line">	previous_dilation = self.dilation</span><br><span class="line">	<span class="keyword">if</span> dilate:</span><br><span class="line">		self.dilation *= stride</span><br><span class="line">		stride = <span class="number">1</span></span><br><span class="line">	<span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != planes * block.expansion:</span><br><span class="line">		downsample = nn.Sequential(</span><br><span class="line">			conv1x1(self.inplanes, planes * block.expansion, stride),</span><br><span class="line">			norm_layer(planes * block.expansion),</span><br><span class="line">		)</span><br><span class="line"></span><br><span class="line">	layers = []</span><br><span class="line">	layers.append(block(self.inplanes, planes, stride, downsample, self.groups,</span><br><span class="line">						self.base_width, previous_dilation, norm_layer))</span><br><span class="line">	self.inplanes = planes * block.expansion</span><br><span class="line">	<span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1</span>, blocks):</span><br><span class="line">		layers.append(block(self.inplanes, planes, groups=self.groups,</span><br><span class="line">							base_width=self.base_width, dilation=self.dilation,</span><br><span class="line">							norm_layer=norm_layer))</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># layer1 = _make_layer(Bottleneck, 64, 3)</span></span><br><span class="line"><span class="comment"># Bottleneck.expansion = 4</span></span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> (self.inplanes = <span class="number">64</span>) != (planes = <span class="number">64</span>) * (Bottleneck.expansion = <span class="number">4</span>) 이므로 downsample이 실행된다.</span><br><span class="line">이때 downsample은 채널의 수를 맞춰주기 위해서 실행되는 과정이다.</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> 이제 layers 리스트에 block()이 하나씩 추가되게 되는데 처음으로 Bottleneck(<span class="number">64</span>, <span class="number">64</span>, <span class="number">1</span>, downsample)이 추가된다.</span><br><span class="line"></span><br><span class="line">layers = [</span><br><span class="line">		Bottleneck(<span class="number">64</span>, <span class="number">64</span>, <span class="number">1</span>, downsample)	</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> 그리고 self.inplanes값이 planes * block.expansion = <span class="number">64</span> * <span class="number">4</span> = <span class="number">256</span>으로 변한다.</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> 다음으로 blocks의 값이 <span class="number">3</span>을 입력받았으므로 두번의 <span class="keyword">for</span> loop를 돌며 두 개의 Bottleneck()이 추가된다.</span><br><span class="line"></span><br><span class="line">layers = [</span><br><span class="line">		Bottleneck(<span class="number">64</span>, <span class="number">64</span>, <span class="number">1</span>, downsample)	</span><br><span class="line">		Bottleneck(<span class="number">256</span>, <span class="number">64</span>)	</span><br><span class="line">		Bottleneck(<span class="number">256</span>, <span class="number">64</span>)</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<ul>
<li>위와 같은 과정을 통해 layer1이 만들어졌는데 실제 ResNet50을 불러서 위에서 계산한 값과 동일하게 Bottleneck()을 통해 생성되었는지 확인해 볼 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line">resnet = torchvision.models.resnet50()</span><br><span class="line">print(resnet)</span><br><span class="line"><span class="comment">#&gt;&gt;&gt;</span></span><br><span class="line">ResNet(</span><br><span class="line">  (conv1): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">7</span>, <span class="number">7</span>), stride=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">3</span>, <span class="number">3</span>), bias=<span class="literal">False</span>)</span><br><span class="line">  (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">  (relu): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (layer1): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (conv3): Conv2d(<span class="number">64</span>, <span class="number">256</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn3): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (<span class="number">0</span>): Conv2d(<span class="number">64</span>, <span class="number">256</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">        (<span class="number">1</span>): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (<span class="number">1</span>): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(<span class="number">256</span>, <span class="number">64</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (conv3): Conv2d(<span class="number">64</span>, <span class="number">256</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn3): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">    (<span class="number">2</span>): Bottleneck(</span><br><span class="line">      (conv1): Conv2d(<span class="number">256</span>, <span class="number">64</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn1): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (conv2): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn2): BatchNorm2d(<span class="number">64</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (conv3): Conv2d(<span class="number">64</span>, <span class="number">256</span>, kernel_size=(<span class="number">1</span>, <span class="number">1</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), bias=<span class="literal">False</span>)</span><br><span class="line">      (bn3): BatchNorm2d(<span class="number">256</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, track_running_stats=<span class="literal">True</span>)</span><br><span class="line">      (relu): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.</span><br></pre></td></tr></table></figure>

<ul>
<li><p>실제 resnet50에서도 layer1에서 총 3개의 Bottleneck이 생성된것을 확인할 수 있다. 각 Bottleneck의 convolution layer값 또한 확인해 볼 수 있었다.</p>
</li>
<li><p>위와 같은 방식으로 총 4개의 layer가 구성되며 각 layer의 깊이는 입력받는 blocks수로 결정된다.</p>
</li>
<li><p>이와같은 ResNet모델의 기본 입력은 3x224x224이다. 하지만 우리가 입력하고자 하는 이미지의 크기가 다를 수 있는데 이와 같은 상황일 때 어떻게 모델을 수정하고 적용할 수 있는지 다음 포스트에서 살펴보고자 한다.</p>
</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-05-24T14:33:43.000Z">2020-05-24</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    4 minutes read (About 570 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/05/24/Pytorch-About-SGD/">Pytorch_About_SGD</a>
            
        </h1>
        <div class="content">
            <h1 id="stochastic-gradient-descent-SGD-에-대하여"><a href="#stochastic-gradient-descent-SGD-에-대하여" class="headerlink" title="stochastic gradient descent(SGD)에 대하여"></a>stochastic gradient descent(SGD)에 대하여</h1><ul>
<li><p>데이터 학습을 할 때 optimizer로 많이 사용되는 SGD에 대해 알아보고자 한다.</p>
</li>
<li><p>SGD는 Batch Gradient Descent(BGD)같이 전체 데이터셋에 대한 미분값을 계산하지 않고, mini-bathc 만큼의 데이터셋에 대해서만 계산을 진행한다.</p>
</li>
<li><p>이렇게 되면 전체 데이터셋을 메모리에 올릴 필요가 없으므로 큰 메모리가 요구되지 않게 됩니다.</p>
</li>
<li><p>stochastic 이라고 말하는 이유 또한 mini-batch만 보기 때문입니다.</p>
<ul>
<li><p>BGD가 전체 데이터셋을 다룬다는 의미는 같은 데이터를 계속 살펴본다는 의미이다. 그렇기 때문에 gradient 값이 하나로 주어지게 되며 이를 deterministic 하다고 말합니다.</p>
</li>
<li><p>하지만, SGD의 경우 mini-batch로 데이터를 보기 때문에 mini-batch를 어떻게 선택하냐에 따라서 gradient값이 다르게 나오게 됩니다.</p>
</li>
<li><p>따라서 gradient의 흐름이 정해지지 않고 확률적으로 나타난다는 의미에서 stochastic 이라고 말하게 됩니다.</p>
</li>
</ul>
</li>
<li><p>SGD의 장점</p>
<ul>
<li><p>mini-batch로 step을 진행하므로 더 빠른 학습이 가능하다.</p>
</li>
<li><p>local-minima을 피할 수 있게 된다.</p>
</li>
<li><p><img src="https://suniljangirblog.files.wordpress.com/2018/12/descent.png" alt="gradient descent"></p>
</li>
<li><p>위의 그림을 보면 BGD는 전체 데이터셋에 대한 계산을 진행하기 때문에 minimum 방향으로 곧장 나아가게 된다. </p>
</li>
<li><p>하지만 SGD는 어떤 batch를 선택했느냐에 따라 minimum을 향해가는 방향이 달라지게 된다. 이렇게 minima의 방향을 알고서 향해가는 것이 아니기 때문에 local minima를 피해갈 수 있게 된다.</p>
</li>
</ul>
</li>
<li><p>SGD의 단점</p>
<ul>
<li><p>SGD는 하나의 축에 대해서는 minima이지만 다른 축에 대해서는 아닌 saddle point를 벗어나지 못하는 문제점이 있다.</p>
</li>
<li><p><img src="https://i.stack.imgur.com/gjDzm.gif" alt="SGD saddle point"></p>
</li>
<li><p>이를 해결하기 위한 SGD의 변형 알고리즘인 Momentum, NAG, Adadelta 등이 존재하며 이는 다음 포스트에서 살펴보려고 한다.</p>
</li>
</ul>
</li>
<li><p>출처</p>
<ul>
<li><p><a href="https://suniljangirblog.wordpress.com/2018/12/13/variants-of-gradient-descent/">gradient descent 이미지</a></p>
</li>
<li><p><a href="https://stats.stackexchange.com/questions/308835/why-does-momentum-escape-from-a-saddle-point-in-this-famous-image">SGD saddle point gif</a></p>
</li>
</ul>
</li>
</ul>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-05-14T18:42:19.000Z">2020-05-14</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    5 minutes read (About 756 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/05/14/Pytorch-VGG-with-CIFAR10/">Pytorch_VGG_with_CIFAR10</a>
            
        </h1>
        <div class="content">
            <h1 id="CIFAR10-데이터셋에-VGG-모델-적용해보기"><a href="#CIFAR10-데이터셋에-VGG-모델-적용해보기" class="headerlink" title="CIFAR10 데이터셋에 VGG 모델 적용해보기"></a>CIFAR10 데이터셋에 VGG 모델 적용해보기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>VGG는 3x224x224의 input을 기본으로 만들어져 있다. 따라서, 이미지의 크기가 다를경우 이미지 크기를 조정하거나 모델을 수정해서 사용할 수 있다.</p>
</li>
<li><p>이번에는 이미지 사이즈는 그대로 사용하며 VGG모델을 조금 수정해서 적용해보자.</p>
</li>
<li><p>VGG의 모델이 어떻게 생성되는지는 <a href="https://already-ready.github.io/2020/05/12/Pytorch-About-VGG-Advance-CNN/">이전 포스트 - VGG 모델 생성 살펴보기</a>에서 확인할 수 있다.</p>
</li>
<li><p>이번에는 custom convolution layer 을 만들고 이를 <code>maye_layers</code>함수를 통해 생성한 후, 이를 통한 모델을 만들고자 한다.</p>
</li>
<li><p>convolution layer 13개와 fully connected layer3개를 가지는 VGG13 configuration을 생성한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfg = [<span class="number">32</span>,<span class="number">32</span>,<span class="string">'M'</span>, <span class="number">64</span>,<span class="number">64</span>,<span class="number">128</span>,<span class="number">128</span>,<span class="number">128</span>,<span class="string">'M'</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="number">256</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="number">512</span>,<span class="string">'M'</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li>그리고, <a href="https://pytorch.org/docs/stable/_modules/torchvision/models/vgg.html#vgg11">VGG Source Code</a>에서 가져온 VGG class를 다음과 같이 일부 수정한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, features, num_classes=<span class="number">1000</span>, init_weights=True)</span>:</span></span><br><span class="line">        super(VGG, self).__init__()</span><br><span class="line">        self.features = features</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">                                nn.Linear(<span class="number">512</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">4096</span>),</span><br><span class="line">                                nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">                                nn.Dropout(),</span><br><span class="line">                                nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">                                nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">                                nn.Dropout(),</span><br><span class="line">                                nn.Linear(<span class="number">4096</span>, num_classes)</span><br><span class="line">                                        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> isinstance(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">'fan_out'</span>, nonlinearity=<span class="string">'relu'</span>)</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> isinstance(m, nn.BatchNorm2d):</span><br><span class="line">                nn.init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> isinstance(m, nn.Linear):</span><br><span class="line">                nn.init.normal_(m.weight, <span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li><p>위의 코드는 Source Code에서 아래와 같은 두 가지 사항을 변경했다</p>
<ul>
<li><p>a. <code>nn.AdaptiveAvgPool2d</code>를 삭제했다.</p>
<ul>
<li>왜냐하면, features layer를 통과하고 우리의 이미지 사이즈는 4x4이므로 <code>nn.AdaptiveAvgPool2d((7, 7))</code>을 통해 사이즈를 키워줄 필요가 없었다.</li>
</ul>
</li>
<li><p>b. classifier layer의 fully connected layer의 input size가 (batch size x 4 x 4) 로 수정되었다.</p>
<ul>
<li>왜냐하면, 위와 마찬가지로 features를 통과한 이미지의 사이즈가 4x4이기 때문이다.</li>
</ul>
</li>
</ul>
</li>
<li><p>이처럼, input size가 다를 경우 기존의 모델을 수정해서 사용할 수 있다. </p>
</li>
<li><p>중요한점은, layer를 통과하면서 image의 size가 어떻게 변하는지를 알고 fully connected layer까지 수정해야 size에러가 발생하지 않는다는 점이다.</p>
</li>
<li><p>이를 위해서, 직접 공식을 통해 계산할 수도 있으며 아래와 같이 <code>forward</code>함수에서 shape를 프린트하며 확인할 수도 있다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">	print(x.shape) <span class="comment"># features layer를 통과하고 shape을 확인해보자.</span></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.</span><br></pre></td></tr></table></figure>

<ul>
<li>이처럼, 사이즈가 다른 CIFAR10 이미지를 수정한 VGG모델에 넣어서 학습시켜볼 수 있었다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Advance_CNN_VGG_with_CIFAR10.ipynb">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-05-12T11:57:01.000Z">2020-05-12</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    9 minutes read (About 1381 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/05/12/Pytorch-About-VGG-Advance-CNN/">Pytorch_About_VGG_Advance_CNN</a>
            
        </h1>
        <div class="content">
            <h1 id="VGG-모델의-생성과정-살펴보기"><a href="#VGG-모델의-생성과정-살펴보기" class="headerlink" title="VGG 모델의 생성과정 살펴보기"></a>VGG 모델의 생성과정 살펴보기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p><a href="https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.vgg11">torchvision.models</a>를 통해 VGG11~VGG19까지 이용할 수 있다.</p>
</li>
<li><p>3x224x224 input을 기준으로 만들어져 있으며, input size가 다른경우 모델을 약간 수정해서 사용할 수 있다.</p>
</li>
<li><p>이번에는 VGG에서 layer가 생성되는 과정을 살펴보려고 한다.</p>
</li>
<li><p>VGG의 <a href="https://pytorch.org/docs/stable/_modules/torchvision/models/vgg.html#vgg11">Source Code</a>이며 일부만 가져와서 살펴보자.</p>
</li>
<li><p>VGG 모델의 Class선언의 <code>__init__</code> 부분을 살펴보자.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, features, num_classes=<span class="number">1000</span>, init_weights=True)</span>:</span></span><br><span class="line">        super(VGG, self).__init__()</span><br><span class="line">        self.features = features</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line">	.</span><br><span class="line">	.</span><br><span class="line">	.</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>features</code>라는 레이어를 통과하고 pooling and linear layer를 통과하는 모습을 확인할 수 있다.</p>
</li>
<li><p>즉 처음 layer는 <code>features</code>부분에서 생성되는데 이는 <code>make_layers</code>라는 함수를 통해 이루어진다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_layers</span><span class="params">(cfg, batch_norm=False)</span>:</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">'M'</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> batch_norm:</span><br><span class="line">                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [conv2d, nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">cfgs = &#123;</span><br><span class="line">    <span class="string">'A'</span>: [<span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>],</span><br><span class="line">    <span class="string">'B'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>],</span><br><span class="line">    <span class="string">'D'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>],</span><br><span class="line">    <span class="string">'E'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>],</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><p><code>make_layers</code>함수를 살펴보면 cfg값에 따라서 알맞는 layer를 return하고 있다.</p>
</li>
<li><p>cfgs에서 ‘A’값을 받았을때 어떻게 Convolution layer가 만들어지는지 따라가보자.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line">순차적으로 <span class="string">'A'</span>의 값이 <span class="keyword">for</span>문을 통해 들어가면 layers에 어떻게 layer가 쌓이는지 누적시키며 따라가보자.</span><br><span class="line">(batch_norm=<span class="literal">False</span>)인 상황이다.</span><br><span class="line"><span class="number">1.</span> 처음에 <span class="number">64</span> 값을 받으면,</span><br><span class="line">layers = [</span><br><span class="line">conv2d= nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">]</span><br><span class="line">가 되며 in_channels가 입력받은 <span class="number">64</span>로 바뀌게된다!</span><br><span class="line"></span><br><span class="line"><span class="number">2.</span> <span class="string">'M'</span> 을 입력받으면, MaxPool2d가 들어가며 in_channels값은 바뀌지 않는다.</span><br><span class="line">layers = [</span><br><span class="line">conv2d= nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="number">3.</span> 다시 <span class="number">128</span> 값을 받으면, 처음 <span class="number">64</span>를 입력받았을때와 마찬가지로 ```Conv2d```와 ```ReLU```가 추가되며 in_channels는 <span class="number">128</span>로 바뀌게된다.</span><br><span class="line">layers = [</span><br><span class="line">conv2d= nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="number">4.</span> 다음으로 <span class="string">'M'</span>을 입력받으면, 두번째 단계와 마찬가지로 MaxPool2d가 들어가고 in_channels는 유지된다.</span><br><span class="line">layers = [</span><br><span class="line">conv2d= nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="number">5.</span> 다음으로 <span class="number">256</span> 값을 두번 연속해서 받으면, 첫번째 단계가 두번 실행되는것과 같다.</span><br><span class="line">layers = [</span><br><span class="line">conv2d= nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="number">6.</span> 세번째 <span class="string">'M'</span>을 입력받아서 다음과 같다.</span><br><span class="line">layers = [</span><br><span class="line">conv2d= nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="number">7.</span> 위의 과정을 통해 익숙해졌으므로 [<span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>] 입력을 한번에 살펴보자. 세 개의 입력이 들어오면 다음과 같이 layers가 쌓이게된다.</span><br><span class="line">layers = [</span><br><span class="line">conv2d= nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="number">8.</span> 마지막으로 다시 한번 [<span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>] 입력을 받는다. 따라서 최종적으로는 다음과 같은 layers가 생성된다.</span><br><span class="line">layers = [</span><br><span class="line">conv2d= nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">conv2d= nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<ul>
<li><p>위의 과정을 따라서 만들어진 모델은 VGG11을 의미하게 되는데, 다음과 같이 계산해 볼 수 있다.</p>
</li>
<li><p>make_layers를 통해 만들어진 Convolution layer의 갯수는 8개였다. 그리고 Source Code를 살펴보면 이후에 fully connected layer가 3개있다.</p>
</li>
<li><p>따라서, 위의 과정으로 만들어진 모델은 8 + 3 = 11 로 VGG11 을 의미한다.</p>
</li>
<li><p>이와 마찬가지로, 나머지 모델은 다음과 같다.</p>
</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">'B' --&gt; 10 + 3 = 13 --&gt; VGG13</span><br><span class="line">'C' --&gt; 13 + 3 = 16 --&gt; VGG16</span><br><span class="line">'D' --&gt; 16 + 3 = 19 --&gt; VGG19</span><br></pre></td></tr></table></figure>

<ul>
<li>Source Code를 따라가면서 VGG모델이 생성되는 과정을 살펴볼 수 있었고 다음에는 input size가 다를경우 VGG를 수정해서 사용하는 방법을 살펴볼 것이다.</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Advance_CNN_VGG_intro.ipynb">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-05-07T20:40:48.000Z">2020-05-07</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    3 minutes read (About 421 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/05/07/Pytorch-ImageFolder/">Pytorch_ImageFolder</a>
            
        </h1>
        <div class="content">
            <h1 id="ImageFolder를-통해-데이터-가져오기"><a href="#ImageFolder를-통해-데이터-가져오기" class="headerlink" title="ImageFolder를 통해 데이터 가져오기"></a>ImageFolder를 통해 데이터 가져오기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>분류된 이미지 데이터셋이 준비되어있다면 ImageFolder를 통해서 데이터를 가져올 수 있다.</p>
</li>
<li><p>예를들어, 3개의 클래스를 가지는 이미지셋을 준비했다면 다음과 같은 폴더 형태로 담아내면 된다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/project</span><br><span class="line">    ㄴdata</span><br><span class="line">	  ㄴdataset_name</span><br><span class="line">			ㄴtrain_data</span><br><span class="line">				ㄴclass1</span><br><span class="line">				ㄴclass2</span><br><span class="line">				ㄴclass3</span><br><span class="line">			ㄴtest_data</span><br><span class="line">				ㄴclass1</span><br><span class="line">				ㄴclass2</span><br><span class="line">				ㄴclass3</span><br><span class="line">    ㄴImageFolder_EX.py</span><br></pre></td></tr></table></figure>

<ul>
<li><p>위와 같이 각 클래스별로 데이터를 준비했다면 <a href="https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder">ImageFolder</a> 를 이용해 데이터를 불러온다.</p>
</li>
<li><p>MNIST나 CIFAR10의 데이터를 불러올 때처럼, tansform을 통해 텐서로 변환해 가져오게 된다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">trans = transforms.Compose([</span><br><span class="line">            transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_data = torchvision.datasets.ImageFolder(root=<span class="string">'data/custom_data/train_data'</span>, transform=trans)</span><br><span class="line"></span><br><span class="line">data_loader = DataLoader(dataset=train_data, batch_size=<span class="number">8</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.ImageFolder(root=<span class="string">'data/custom_data/test_data'</span>, transform=trans)</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(dataset=test_data, batch_size=len(test_data))</span><br></pre></td></tr></table></figure>

<ul>
<li>이후 간단한 CNN 모델을 만들어서 자신이 가진 데이터셋을 학습시킬 수 있다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(CNN, self).__init__()</span><br><span class="line">        self.layer1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        )</span><br><span class="line">		.</span><br><span class="line">		.</span><br><span class="line">		.</span><br><span class="line">		<span class="comment"># Full Code 참조</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>이전까지는 Pytorch에서 바로 다운로드하고 불러올 수 있는 MNIST, CIFAR10과 같은 데이터셋을 이용했다.</p>
</li>
<li><p>하지만, 이번에는 자신이 가진 고유의 데이터셋을 ImageFolder를 통해 불러오고 학습시키는 과정을 알 수 있었다.  </p>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/ImageFolder_2.py">Full Code</a></p>

        </div>
        
        
        
    </div>
</div>








    
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2020-05-06T16:14:42.000Z">2020-05-06</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/Python/">Python</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    8 minutes read (About 1266 words)
                </span>
                
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                <a class="has-link-black-ter" href="/2020/05/06/Pytorch-visdom%EC%9C%BC%EB%A1%9C-Loss-plot%EA%B7%B8%EB%A6%AC%EA%B8%B0/">Pytorch_visdom으로_Loss_plot그리기</a>
            
        </h1>
        <div class="content">
            <h1 id="Visdom에-관하여-amp-Loss-plot-그리기"><a href="#Visdom에-관하여-amp-Loss-plot-그리기" class="headerlink" title="Visdom에 관하여 &amp; Loss plot 그리기"></a>Visdom에 관하여 &amp; Loss plot 그리기</h1><h3 id="모두를-위한-딥러닝-파이토치-강의-참고"><a href="#모두를-위한-딥러닝-파이토치-강의-참고" class="headerlink" title="모두를 위한 딥러닝 - 파이토치 강의 참고"></a><a href="https://www.youtube.com/watch?v=7eldOrjQVi0&list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv">모두를 위한 딥러닝 - 파이토치</a> 강의 참고</h3><ul>
<li><p>visdom을 사용하기 위해서는 서버를 실행시켜줘야 한다.</p>
</li>
<li><p>jupyter notebook의 경우, New –&gt; Terminal –&gt; 실행된 터미널 창에서 다음의 명령어를 입력한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;python -m visdom.server</span><br></pre></td></tr></table></figure>

<ul>
<li><p>pycharm을 이용한다면 파이참 하단의 terminal을 클릭해 위의 명령어를 입력하면된다.</p>
</li>
<li><p>다만, visdom의 기본 포트가 사용중이라면 에러가 발생하는데 이때는 <a href="https://already-ready.github.io/2020/04/25/%ED%8C%8C%EC%9D%B4%EC%8D%AC-visdom-port-%EB%B3%80%EA%B2%BD%ED%95%98%EA%B8%B0/">visdom 포트변경</a> 포스트를 확인해 해결할 수 있다.</p>
</li>
<li><p>서버가 정상적으로 실행됐다면, visdom 객체를 아래와 같이 생성하고 이를 이용해 text, 이미지, 그래프 등을 나타낼 수 있다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> visdom</span><br><span class="line">vis = visdom.Visdom()</span><br></pre></td></tr></table></figure>

<ul>
<li><p>아래에서 진행하는 예제는 실행된 local서버를 접속해 확인할 수 있다.</p>
</li>
<li><p>Text 출력하기</p>
<ul>
<li><p>text를 출력하기 위해서 <code>text()</code>를 사용한다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vis.text(<span class="string">'hello world'</span>, env=<span class="string">'main'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>이때 <code>env=&#39;main&#39;</code>은 실행문의 이름을 지정해 추후에 main으로 실행된 모든 창을 한번에 종료할 수 있게 해준다.</p>
</li>
</ul>
</li>
<li><p>Image 출력하기</p>
<ul>
<li><p>image 출력은 <code>image()</code>를 사용한다.</p>
</li>
<li><p>랜덤한 이미지를 출력해보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ex = torch.randn(<span class="number">3</span>, <span class="number">200</span>, <span class="number">200</span>)</span><br><span class="line">vis.image(ex)</span><br></pre></td></tr></table></figure>
</li>
<li><p>여러장의 이미지를 출력하기 위해서는 <code>images()</code>를 사용한다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vis.images(torch.Tensor(<span class="number">3</span>,<span class="number">3</span>,<span class="number">28</span>,<span class="number">28</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>CIFAR10의 이미지를 가져와 출력해보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cifar10 = dsets.CIFAR10(root=<span class="string">"cifar10/"</span>,train = <span class="literal">True</span>, transform=torchvision.transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">data = cifar10.__getitem(<span class="number">0</span>)__</span><br><span class="line">vis.images(data[<span class="number">0</span>], env=<span class="string">'main'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>DataLoader로부터 여러개의 이미지를 출력할 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">MNIST = dsets.MNIST(root=<span class="string">"MNIST_data/"</span>,train = <span class="literal">True</span>,transform=torchvision.transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">data_loader = torch.utils.data.DataLoader(dataset = MNIST,</span><br><span class="line">                                         batch_size = <span class="number">32</span>,</span><br><span class="line">                                         shuffle = <span class="literal">False</span>)</span><br><span class="line">									  </span><br><span class="line"><span class="keyword">for</span> num, value <span class="keyword">in</span> enumerate(data_loader):</span><br><span class="line">	value = value[<span class="number">0</span>]</span><br><span class="line">	vis.images(value)</span><br><span class="line">	<span class="keyword">break</span></span><br><span class="line"><span class="comment">###&gt;&gt;&gt; batch_size만큼의 이미지가 한번에 출력된다</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Line Plot 그리기</p>
<ul>
<li><p>line plot은 <code>line()</code>을 사용한다.</p>
</li>
<li><p>임의의 y값을 가지는 그래프를 그려보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Y_data = torch.randn(<span class="number">5</span>)</span><br><span class="line">X_data = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">plt = vis.line(Y=Y_data, X=X_data)</span><br></pre></td></tr></table></figure>
</li>
<li><p>위를 통해 plt라는 이름의 그래프가 그려지는 것을 확인할 수 있다. 만약 이때 X 범위를 설정해주지 않았다면 X의 범위는 0과 1사이에서 출력되게 된다.</p>
</li>
<li><p>이미 그려진 line plot을 업데이트도 할 수 있다. 똑같이 <code>line()</code>을 사용한다. 위에서 그린 plt 그래프에 하나의 값을 업데이트 해보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Y_append = torch.randn(<span class="number">1</span>)</span><br><span class="line">X_append = torch.Tensor([<span class="number">6</span>])</span><br><span class="line"></span><br><span class="line">vis.line(Y=Y_append, X=X_append, win=plt, update=<span class="string">'append'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>위와같이 업데이트할 plot의 이름을 <code>win</code>에 지정해주고 <code>update=&#39;append&#39;</code>로 지정하면 기존의 그래프에 하나의 값이 추가된 것을 확인할 수 있다.</p>
</li>
<li><p>하나의 window에 두개의 line plot을 그릴때도 <code>line()</code>을 사용한다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">num = torch.Tensor(list(range(<span class="number">0</span>,<span class="number">10</span>)))</span><br><span class="line">num = num.view(<span class="number">-1</span>,<span class="number">1</span>)</span><br><span class="line">num = torch.cat((num,num),dim=<span class="number">1</span>)</span><br><span class="line">print(num.shape) <span class="comment">###&gt;&gt;&gt; (10,2)</span></span><br><span class="line"></span><br><span class="line">plt = vis.line(Y=torch.randn(<span class="number">10</span>,<span class="number">2</span>), X = num)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>Line Plot의 정보 나타내기</p>
<ul>
<li><p>line plot에 title과 legend를 나타내기 위해서는 dict형태의 입력값을 사용한다.</p>
</li>
<li><p>위에 그린 그래프에 title과 legned를 나타내보자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt = vis.line(Y=Y_data, X=X_data, opts=dict(title=<span class="string">'test'</span>, legend=[<span class="string">'1번'</span>], showlegend=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>두개의 line plot에도 각각의 legend를 나타낼 수 있다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt = vis.line(Y=torch.randn(<span class="number">10</span>,<span class="number">2</span>), X=num, optes=dict(title=<span class="string">'test'</span>, legend=[<span class="string">'1번'</span>,<span class="string">'2번'</span>], showlegend=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>창 닫기</p>
<ul>
<li><p><code>env=&#39;main&#39;</code>으로 지정한 창을 닫기 위해서 <code>close()</code>를 사용한다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vis.close(env=<span class="string">'main'</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>기본적인 visdom 사용법을 알아보았으며, 이를 이용해 <a href="https://already-ready.github.io/2020/05/01/Pytorch-MNIST-CNN/">CNN MNIST</a>의 코드를 조금 변형해 loss plot을 그려보자.</p>
<ul>
<li><p>loss plot을 그리기 위해서 line plot을 업데이트해줄 함수를 만들어주자.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_tracker</span><span class="params">(loss_plot, loss_value, num)</span>:</span></span><br><span class="line">	<span class="comment">### loss_plot : line plot value</span></span><br><span class="line">	<span class="comment">### loss_value : Tensor</span></span><br><span class="line">	<span class="comment">### num : Tensor</span></span><br><span class="line">	<span class="comment">### return : None</span></span><br><span class="line">	vis.line(X=num, Y=loss_value, win=loss_plot, update=<span class="string">'append'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>그리고 loss를 업데이트해줄 빈 line plot을 하나 만들어준다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss_plot = vis.line(Y=torch.Tensor(<span class="number">1</span>).zero_(), opts=dict(title=<span class="string">'loss'</span>, legend=[<span class="string">'loss'</span>], showlegend=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure>
</li>
<li><p>이후 모델 생성은 모두 동일하지만, train을 진행할때 위의 함수를 통해 그래프를 업데이트 해주는 부분이 추가된다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">total_batch = len(data_loader)</span><br><span class="line">model.train()</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">	avg_cost = <span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> X, Y <span class="keyword">in</span> data_loader:</span><br><span class="line">		X = X.to(device)</span><br><span class="line">		Y = Y.to(device)</span><br><span class="line"></span><br><span class="line">		optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">		hypothesis = model(X)</span><br><span class="line">		loss = criterion(hypothesis, Y)</span><br><span class="line">		loss.backward()</span><br><span class="line">		optimizer.step()</span><br><span class="line"></span><br><span class="line">		avg_cost += loss / total_batch</span><br><span class="line"></span><br><span class="line">	print(<span class="string">'[Epoch: &#123;:&gt;4&#125;] cost = &#123;:&gt;.9&#125;'</span>.format(epoch + <span class="number">1</span>, avg_cost))</span><br><span class="line">	loss_tracker(loss_plot, torch.Tensor([avg_cost]), torch.Tensor([epoch])) </span><br><span class="line">	<span class="comment">###&gt;&gt;&gt; loss_tracker함수를 통해 그래프를 업데이트</span></span><br><span class="line">print(<span class="string">'learning finished'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>학습을 진행하면서 visdom의 line plot이 실시간으로 업데이트되는 모습을 확인할 수 있다.</p>
</li>
</ul>
</li>
</ul>
<h1 id="Full-Code"><a href="#Full-Code" class="headerlink" title="Full Code"></a>Full Code</h1><p><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/About_Visdom_example.py">Full Code - Visdom Example</a><br><a href="https://github.com/Already-Ready/pytorch_zero_to_all/blob/master/Convolution_with_Visdom.py">Full Code - Loss tracker</a></p>

        </div>
        
        
        
    </div>
</div>









    
<div class="card card-transparent">
    <nav class="pagination is-centered" role="navigation" aria-label="pagination">
        <div class="pagination-previous is-invisible is-hidden-mobile">
            <a class="is-flex-grow has-text-black-ter" href="/tags/Pytorch/page/0/">Previous</a>
        </div>
        <div class="pagination-next">
            <a class="is-flex-grow has-text-black-ter" href="/tags/Pytorch/page/2/">Next</a>
        </div>
        <ul class="pagination-list is-hidden-mobile">
            
            <li><a class="pagination-link is-current" href="/tags/Pytorch/">1</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/tags/Pytorch/page/2/">2</a></li>
            
            <li><a class="pagination-link has-text-black-ter" href="/tags/Pytorch/page/3/">3</a></li>
            
        </ul>
    </nav>
</div>
</div>
                




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="" src="/images/avatar.png" alt="Already-Ready">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        Already-Ready
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        I&#39;m Going Now
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Seongnam city</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Posts
                    </p>
                    <a href="/archives">
                        <p class="title has-text-weight-normal">
                            51
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Categories
                    </p>
                    <a href="/categories">
                        <p class="title has-text-weight-normal">
                            12
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Tags
                    </p>
                    <a href="/tags">
                        <p class="title has-text-weight-normal">
                            8
                        </p>
                    </a>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">
                Follow</a>
        </div>
        
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Github" href="https://github.com/Already-Ready">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Facebook" href="https://facebook.com">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Twitter" href="https://twitter.com">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="Dribbble" href="https://dribbble.com">
                
                <i class="fab fa-dribbble"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank" rel="noopener"
                title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Links
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://github.com/Already-Ready" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">My_Github</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">github.com</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/CS-basic/">
            <span class="level-start">
                <span class="level-item">CS basic</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">6</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/CS-basic/CtCI/">
            <span class="level-start">
                <span class="level-item">CtCI</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Go/">
            <span class="level-start">
                <span class="level-item">Go</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Go/About-Go/">
            <span class="level-start">
                <span class="level-item">About Go</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Go/tutorial/">
            <span class="level-start">
                <span class="level-item">tutorial</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Python/">
            <span class="level-start">
                <span class="level-item">Python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">26</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Python/About-Python/">
            <span class="level-start">
                <span class="level-item">About Python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Python/Pytorch/">
            <span class="level-start">
                <span class="level-item">Pytorch</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">22</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/baekjoon/">
            <span class="level-start">
                <span class="level-item">baekjoon</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">11</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/baekjoon/Go/">
            <span class="level-start">
                <span class="level-item">Go</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">5</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/baekjoon/python/">
            <span class="level-start">
                <span class="level-item">python</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">11</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/github-io/">
            <span class="level-start">
                <span class="level-item">github.io</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li>
            </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/CS/" style="font-size: 14px;">CS</a> <a href="/tags/CtCI/" style="font-size: 12px;">CtCI</a> <a href="/tags/Go/" style="font-size: 16px;">Go</a> <a href="/tags/Python/" style="font-size: 20px;">Python</a> <a href="/tags/Pytorch/" style="font-size: 18px;">Pytorch</a> <a href="/tags/baekjoon/" style="font-size: 16px;">baekjoon</a> <a href="/tags/github-io/" style="font-size: 10px;">github.io</a> <a href="/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/" style="font-size: 10px;">블로그</a>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
            <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2020/07/05/Pytorch-RNN-long-sequence/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_RNN_long_sequence">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-07-05T15:00:04.000Z">2020-07-05</time></div>
                    <a href="/2020/07/05/Pytorch-RNN-long-sequence/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_RNN_long_sequence</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/07/02/Pytorch-RNN-intro/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_RNN_intro">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-07-02T11:48:28.000Z">2020-07-02</time></div>
                    <a href="/2020/07/02/Pytorch-RNN-intro/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_RNN_intro</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/06/25/Pytorch-Activation-plot/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_Activation_plot">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-06-25T16:43:18.000Z">2020-06-25</time></div>
                    <a href="/2020/06/25/Pytorch-Activation-plot/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_Activation_plot</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/06/22/Pytorch-RESNET-with-CIFAR10/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_RESNET_with_CIFAR10">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-06-22T15:46:49.000Z">2020-06-22</time></div>
                    <a href="/2020/06/22/Pytorch-RESNET-with-CIFAR10/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_RESNET_with_CIFAR10</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/06/08/Pytorch-About-RESNET/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_About_RESNET">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-06-08T21:15:31.000Z">2020-06-08</time></div>
                    <a href="/2020/06/08/Pytorch-About-RESNET/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_About_RESNET</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2020/07/">
                <span class="level-start">
                    <span class="level-item">July 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/06/">
                <span class="level-start">
                    <span class="level-item">June 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/05/">
                <span class="level-start">
                    <span class="level-item">May 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">6</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">April 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">12</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">March 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/02/">
                <span class="level-start">
                    <span class="level-item">February 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/01/">
                <span class="level-start">
                    <span class="level-item">January 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">17</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/12/">
                <span class="level-start">
                    <span class="level-item">December 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CS/">
                        <span class="tag">CS</span>
                        <span class="tag is-grey">6</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CtCI/">
                        <span class="tag">CtCI</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Go/">
                        <span class="tag">Go</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Python/">
                        <span class="tag">Python</span>
                        <span class="tag is-grey">35</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Pytorch/">
                        <span class="tag">Pytorch</span>
                        <span class="tag is-grey">22</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/baekjoon/">
                        <span class="tag">baekjoon</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/github-io/">
                        <span class="tag">github.io</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/">
                        <span class="tag">블로그</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
        
        </div>
    
</div>

                




<div class="column is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only has-order-3 column-right ">
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2020/07/05/Pytorch-RNN-long-sequence/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_RNN_long_sequence">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-07-05T15:00:04.000Z">2020-07-05</time></div>
                    <a href="/2020/07/05/Pytorch-RNN-long-sequence/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_RNN_long_sequence</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/07/02/Pytorch-RNN-intro/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_RNN_intro">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-07-02T11:48:28.000Z">2020-07-02</time></div>
                    <a href="/2020/07/02/Pytorch-RNN-intro/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_RNN_intro</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/06/25/Pytorch-Activation-plot/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_Activation_plot">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-06-25T16:43:18.000Z">2020-06-25</time></div>
                    <a href="/2020/06/25/Pytorch-Activation-plot/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_Activation_plot</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/06/22/Pytorch-RESNET-with-CIFAR10/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_RESNET_with_CIFAR10">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-06-22T15:46:49.000Z">2020-06-22</time></div>
                    <a href="/2020/06/22/Pytorch-RESNET-with-CIFAR10/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_RESNET_with_CIFAR10</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2020/06/08/Pytorch-About-RESNET/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Pytorch_About_RESNET">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2020-06-08T21:15:31.000Z">2020-06-08</time></div>
                    <a href="/2020/06/08/Pytorch-About-RESNET/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Pytorch_About_RESNET</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Python/">Python</a> / <a class="has-link-grey -link" href="/categories/Python/Pytorch/">Pytorch</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2020/07/">
                <span class="level-start">
                    <span class="level-item">July 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">2</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/06/">
                <span class="level-start">
                    <span class="level-item">June 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/05/">
                <span class="level-start">
                    <span class="level-item">May 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">6</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">April 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">12</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">March 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/02/">
                <span class="level-start">
                    <span class="level-item">February 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">3</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/01/">
                <span class="level-start">
                    <span class="level-item">January 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">17</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/12/">
                <span class="level-start">
                    <span class="level-item">December 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">4</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CS/">
                        <span class="tag">CS</span>
                        <span class="tag is-grey">6</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CtCI/">
                        <span class="tag">CtCI</span>
                        <span class="tag is-grey">5</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Go/">
                        <span class="tag">Go</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Python/">
                        <span class="tag">Python</span>
                        <span class="tag is-grey">35</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Pytorch/">
                        <span class="tag">Pytorch</span>
                        <span class="tag is-grey">22</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/baekjoon/">
                        <span class="tag">baekjoon</span>
                        <span class="tag is-grey">10</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/github-io/">
                        <span class="tag">github.io</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/%EB%B8%94%EB%A1%9C%EA%B7%B8/">
                        <span class="tag">블로그</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
    
    
</div>

            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="Hexo" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2020 John Doe&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'http://yoursite.com',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>














<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>